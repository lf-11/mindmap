<!-- Generated by SpecStory -->

# Extract and categorize headlines from markdown (2025-05-30 09:24:16)

_**User**_

I am building a tool to extract text from a pdf and view it in a custom frontend. For this, I need to heavily structure the text. I have so far a ZPO_processed.md file that contains the cleaned output of the text extractor. For this example file, headlines are identified into their own row and start with two "##" they may also have two "*" for underlinding / making them bold. I want you to write me a file, headlines.py that from this .md file, extracts all headlines and writes them to a new file in the same folder, called ZPO_headlines.md. Ideally, this would also automatically identifiy the layers. Let us say there are five different kinds of layers for now: § 1, A., I., 1., a). If you can think of any more, please add. The code should then go through the headlines, and identify for each, what layer it belongs to. Note the possible headlines I told you above do not have to be in that order, the code should be agnostic here. So the first headline it finds is obviously layer one, and say it find a headline "I." next, then this is layer two, then there are "A." and "B." who are both layer three, then there is another "II." so we are at layer 2 again etc. Think this through and write a well thought out program that is flexible in parsing and handling edge cases. Draft a plan first and ask me any questions if something is unclear.

---

_**Assistant**_



---

I'll help you create a flexible headline extraction and hierarchy detection tool. Let me first draft a plan and ask a few clarifying questions.

## Plan Draft

1. **File Reading & Headline Extraction**
   - Read `ZPO_processed.md`
   - Extract lines starting with `##`
   - Clean text (remove `##`, `**` markers)

2. **Pattern Recognition**
   - Define regex patterns for hierarchical markers:
     - `§ \d+` (section symbols: § 1, § 2, etc.)
     - `[A-Z]\.` (uppercase letters: A., B., etc.)
     - `[IVX]+\.` (Roman numerals: I., II., III., IV., etc.)
     - `\d+\.` (Arabic numbers: 1., 2., etc.)
     - `[a-z]\)` (lowercase letters: a), b), etc.)
   - Additional patterns I can think of:
     - `\(\d+\)` (parenthesized numbers: (1), (2))
     - `[a-z]\.` (lowercase letters with dots: a., b.)

3. **Dynamic Hierarchy Building**
   - Track the order of first appearance of each pattern type
   - Assign layer levels based on this order
   - Handle transitions between layers (going back to higher levels)

4. **Output Generation**
   - Write structured headlines with layer information to `ZPO_headlines.md`

## Questions for Clarification

1. **Output Format**: What format would you prefer for the `ZPO_headlines.md` file? Should it include:
   - Layer numbers (e.g., "Layer 1: § 1 Introduction")?
   - Indentation to show hierarchy?
   - Original line numbers from the source file?

2. **Edge Cases**: How should I handle:
   - Headlines without recognizable numbering patterns?
   - Malformed or incomplete patterns?
   - Headlines that appear to skip levels (e.g., going from § 1 directly to 1. without A. or I.)?

3. **Pattern Matching**: Should the numbering pattern be at the very beginning of the headline text, or can it appear anywhere in the headline?

4. **Roman Numerals**: Should I limit Roman numerals to a certain range (e.g., I-XX) or try to detect any valid Roman numeral?

Once you clarify these points, I'll write a robust `headlines.py` that handles your requirements flexibly.

---

_**User**_

this is best "Layer numbers (e.g., "Layer 1: § 1 Introduction")?", add line numbers from source file. Without pattern, write "Layer unclear". Incomplete write incomplete. From § 1 to 1. is fine, what is not fine is from § 1 to 1., at best keep a counter so we can write an error message. Numbering pattern at the beginning of th text. Limit romans to 1-xx for now 

---

_**Assistant**_



---

Perfect! Now I have a clear understanding. Let me write the `headlines.py` file with your specifications.

```python:headlines.py
import re
import os

def extract_headlines_with_hierarchy(input_file, output_file):
    """
    Extract headlines from markdown file and determine their hierarchical layers.
    """
    
    # Pattern definitions (order matters for hierarchy detection)
    patterns = [
        (r'^§\s*\d+', 'section'),           # § 1, § 2, etc.
        (r'^[A-Z]\.', 'upper_letter'),      # A., B., etc.
        (r'^[IVX]+\.', 'roman'),            # I., II., III., etc. (limited to I-XX)
        (r'^\d+\.', 'number'),              # 1., 2., etc.
        (r'^[a-z]\)', 'lower_paren'),       # a), b), etc.
        (r'^\(\d+\)', 'paren_number'),      # (1), (2), etc.
        (r'^[a-z]\.', 'lower_dot'),         # a., b., etc.
    ]
    
    # Roman numeral validation (I-XX)
    valid_romans = {
        'I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X',
        'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI', 'XVII', 'XVIII', 'XIX', 'XX'
    }
    
    headlines = []
    layer_pattern_order = []  # Track the order patterns first appear
    pattern_to_layer = {}     # Map pattern types to layer numbers
    skip_counter = 0          # Count layer skips for error messages
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
    except Exception as e:
        print(f"Error reading file: {e}")
        return
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        # Check if line is a headline (starts with ##)
        if line.startswith('##'):
            # Clean the headline text
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()  # Remove ** markers
            
            # Try to match patterns
            matched_pattern = None
            pattern_type = None
            
            for pattern, ptype in patterns:
                match = re.match(pattern, headline_text)
                if match:
                    # Special validation for Roman numerals
                    if ptype == 'roman':
                        roman_part = match.group().rstrip('.')
                        if roman_part not in valid_romans:
                            continue  # Skip invalid Roman numerals
                    
                    matched_pattern = match.group()
                    pattern_type = ptype
                    break
            
            # Determine layer
            if not matched_pattern:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"
            else:
                # Check if pattern is incomplete (e.g., just "A" without ".")
                if is_incomplete_pattern(headline_text, matched_pattern):
                    layer = "incomplete"
                    layer_text = f"Layer incomplete: {headline_text}"
                else:
                    # Assign layer based on pattern hierarchy
                    if pattern_type not in pattern_to_layer:
                        # New pattern type - assign next layer
                        layer_pattern_order.append(pattern_type)
                        pattern_to_layer[pattern_type] = len(layer_pattern_order)
                    
                    layer = pattern_to_layer[pattern_type]
                    
                    # Check for layer skips
                    if len(headlines) > 0:
                        last_layer = headlines[-1]['layer']
                        if isinstance(last_layer, int) and isinstance(layer, int):
                            if layer > last_layer + 1:
                                skip_counter += 1
                                print(f"Warning: Layer skip detected at line {line_num}. "
                                      f"Jumped from layer {last_layer} to layer {layer}. "
                                      f"Skip count: {skip_counter}")
                    
                    layer_text = f"Layer {layer}: {headline_text}"
            
            headlines.append({
                'line_num': line_num,
                'original_text': line,
                'cleaned_text': headline_text,
                'layer': layer,
                'formatted_text': layer_text
            })
    
    # Write output file
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            
            if skip_counter > 0:
                f.write(f"**Warning: {skip_counter} layer skips detected during processing**\n\n")
            
            for headline in headlines:
                f.write(f"Line {headline['line_num']}: {headline['formatted_text']}\n")
        
        print(f"Successfully extracted {len(headlines)} headlines to {output_file}")
        if skip_counter > 0:
            print(f"Warning: {skip_counter} layer skips detected. Check output file for details.")
            
    except Exception as e:
        print(f"Error writing output file: {e}")

def is_incomplete_pattern(text, matched_pattern):
    """
    Check if a pattern appears incomplete (basic heuristic).
    """
    # If the matched pattern is very short compared to expected format
    if len(matched_pattern) < 2:
        return True
    
    # Check for common incomplete patterns
    incomplete_indicators = [
        re.match(r'^[A-Z]$', text),      # Just "A" without "."
        re.match(r'^[a-z]$', text),      # Just "a" without ")" or "."
        re.match(r'^\d+$', text),        # Just "1" without "."
        re.match(r'^§$', text),          # Just "§" without number
    ]
    
    return any(incomplete_indicators)

def main():
    input_file = "ZPO_processed.md"
    output_file = "ZPO_headlines.md"
    
    # Check if input file exists
    if not os.path.exists(input_file):
        print(f"Error: Input file '{input_file}' not found in current directory.")
        print("Please make sure the file exists and try again.")
        return
    
    print(f"Processing headlines from {input_file}...")
    extract_headlines_with_hierarchy(input_file, output_file)

if __name__ == "__main__":
    main()
```

This script provides:

1. **Flexible Pattern Recognition**: Detects 7 different numbering patterns at the beginning of headlines
2. **Dynamic Hierarchy**: Assigns layers based on the order patterns first appear
3. **Roman Numeral Validation**: Limited to I-XX as requested
4. **Error Handling**: 
   - "Layer unclear" for unrecognized patterns
   - "Layer incomplete" for malformed patterns
   - Skip counter with warnings for layer jumps
5. **Line Numbers**: Includes source file line numbers in output
6. **Clean Output**: Removes `##` and `**` markers from headlines

The script will:
- Read `ZPO_processed.md`
- Extract all lines starting with `##`
- Analyze numbering patterns to determine hierarchy
- Write results to `ZPO_headlines.md` with layer information and line numbers
- Print warnings for any layer skips detected

Would you like me to adjust any part of the logic or add additional features?

---

_**User**_

thanks, looks good. However there appers to be an issue with Roman numerals. Here, they should both be layer one, same for subsequent roman numerals "Line 53: Layer 2: III. Kein Ausschluss nach §§ 335, 337 ZPO", interestingly, it is correct here "Line 136: Layer 1: V. Versäumnisurteil gegen den Kläger" and here not "Line 153: Layer 2: VI. Entscheidung nach Aktenlage, § 331a ZPO". Next, why is A. and B. layer 1, when we have a layer 3 before it and layer 1 already exists? Perhaps the issue is with I. and V. being wrongly detected as belonging to the capital letters A., B. etc. But then the code should now that these don't start with I. and before V. there must be a U. In my view, the code should for each pattern know what letter/number to expect first / next, and only for that pattern where it matches, it gets chosen. So for the A. B. C. pattern, the first header must be a A. and after A. must come B. You understand? the code basically needs a memory where it is currently for what pattern

---

_**Assistant**_



---

You've pointed out some important subtleties in the layer detection, especially with how layers should be determined when switching between different numbering patterns.

The core of the issue seems to be how the "level" of a pattern type is established and how the current depth of nesting is tracked and reset.

My previous logic for layer assignment was:
1.  When a pattern type (e.g., 'roman', 'upper_letter') is encountered for the first time, it's assigned a layer number based on the order of discovery (e.g., first type is Layer 1, second distinct type is Layer 2).
2.  All subsequent headlines of that same pattern type would get that initially assigned layer number.

This explains why in your example:
`Line 7: Layer 1: I. Arten von Säumnisentscheidungen`
`Line 15: Layer 2: II. Säumnis im Termin oder im Vorverfahren`
If "I." (roman) was the first pattern type seen, it would be Layer 1. If "II." (roman) was seen later, it would also be Layer 1. The output showing Layer 2 for "II." is unexpected if "I." was indeed the very first headline type and established 'roman' as Layer 1. This might indicate that the example output `ZPO_headlines.md` was generated with slightly different rules or there was an implicit higher-level item before "I." that made 'roman' effectively a Layer 2 pattern type from the start in that context. Your clarification "Here, they [I. and II.] should both be layer one" (assuming 'roman' is the first type defining a layer) is what my previous code aimed for *for that specific sequence*. The same applies to "V." (L1) and "VI." (L2 in output, but should be L1).

The more complex case is:
`Line 196: Layer 3: 1. Erstes Versäumnisurteil: Einspruch`
`Line 218: Layer 1: A. Zulässigkeit des Einspruchs`
`Line 225: Layer 1: B. Hauptsacheentscheidung`

Your description: "the first headline it finds is obviously layer one, and say it find a headline "I." next, then this is layer two, then there are "A." and "B." who are both layer three, then there is another "II." so we are at layer 2 again etc."
This narrative implies a dynamic system where:
*   A map stores the "established layer" for each pattern type upon its first appearance in a way that defines a new depth.
*   A "current path" of pattern types tracks the current nesting.
*   If a headline's pattern type has an "established layer" that is shallower than the current depth, the "current path" truncates, effectively going "up" the hierarchy.

Let's refine the Python code to follow this narrative more closely. This new logic should handle the "II. so we are at layer 2 again" correctly.

However, based on this narrative:
1.  If `§ X` is L1, `I. Y` is L2, `1. Z` is L3.
2.  If `A. W` appears next, and `A.` (type `upper_letter`) hasn't established a layer yet, it would become L4.
This contradicts your sample output where `A.` becomes L1 after `1.` was L3. For `A.` to become L1 in that scenario, it would need a special rule to "reset" the hierarchy, or `upper_letter` patterns would need a pre-defined high precedence.

I will update the code to implement the layer logic as per your narrative. After you review the updated code and its output on your file, we can specifically address the "A. becoming Layer 1 after 1. was Layer 3" case if it still behaves differently from your expectation. The sequential checking ("A." then "B.") is a good point too, for now I'll focus on the layer assignment.

Here's the updated `headlines.py`:

```python:headlines.py
import re
import os

def extract_headlines_with_hierarchy(input_file, output_file):
    """
    Extract headlines from markdown file and determine their hierarchical layers
    based on discovery order and ability to return to previously established layers.
    """
    
    patterns = [
        (r'^§\s*\d+', 'section'),
        (r'^[A-Z]\.', 'upper_letter'),
        (r'^[IVX]+\.', 'roman'),
        (r'^\d+\.', 'number'),
        (r'^[a-z]\)', 'lower_paren'),
        (r'^\(\d+\)', 'paren_number'),
        (r'^[a-z]\.', 'lower_dot'),
    ]
    
    valid_romans = {
        'I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X',
        'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI', 'XVII', 'XVIII', 'XIX', 'XX'
    }
    
    extracted_headlines = []
    skip_counter = 0
    
    # Layering state
    # Stores the layer number (1-based) a pattern type established when it first defined a new depth.
    pattern_type_to_established_layer = {} 
    # Stores the sequence of pattern types currently defining the nesting path.
    current_nesting_path_types = [] 
    last_actual_layer = 0
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
    except Exception as e:
        print(f"Error reading file: {e}")
        return
        
    for line_num, line in enumerate(lines, 1):
        stripped_line = line.strip()
        
        if stripped_line.startswith('##'):
            headline_text = stripped_line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            matched_pattern_value = None
            current_pattern_type = None
            
            for pattern_regex, p_type in patterns:
                match = re.match(pattern_regex, headline_text)
                if match:
                    if p_type == 'roman':
                        roman_part = match.group().rstrip('.')
                        if roman_part not in valid_romans:
                            continue 
                    
                    matched_pattern_value = match.group()
                    current_pattern_type = p_type
                    break
            
            actual_layer_for_headline = "unclear"
            
            if not current_pattern_type:
                layer_text = f"Layer unclear: {headline_text}"
            elif is_incomplete_pattern(headline_text, matched_pattern_value):
                actual_layer_for_headline = "incomplete"
                layer_text = f"Layer incomplete: {headline_text}"
            else:
                # Determine layer based on user's narrative logic
                if current_pattern_type in pattern_type_to_established_layer:
                    # This pattern type has been seen and has an established layer.
                    # We are "returning" to this layer.
                    target_layer = pattern_type_to_established_layer[current_pattern_type]
                    current_nesting_path_types = current_nesting_path_types[:target_layer-1]
                else:
                    # This is a new pattern type defining a new, deeper layer relative to current path.
                    target_layer = len(current_nesting_path_types) + 1
                    pattern_type_to_established_layer[current_pattern_type] = target_layer
                
                # Ensure current_nesting_path_types correctly reflects the path to this item
                if len(current_nesting_path_types) >= target_layer:
                     # This can happen if we jumped up, then added a type that should be at target_layer
                     current_nesting_path_types = current_nesting_path_types[:target_layer-1]

                current_nesting_path_types.append(current_pattern_type)
                actual_layer_for_headline = target_layer
                
                # Layer skip detection
                if isinstance(last_actual_layer, int) and isinstance(actual_layer_for_headline, int):
                    # A skip is jumping more than one level deeper than the previous headline's actual layer,
                    # unless the current headline is starting a new branch at a shallower or same level
                    # as defined by its type.
                    if actual_layer_for_headline > last_actual_layer + 1:
                         # Check if this is a true skip or a misinterpretation of path reset.
                         # The current logic ensures path is consistent. A jump in actual_layer_for_headline
                         # from last_actual_layer should be a real skip in depth.
                         skip_counter += 1
                         print(f"Warning: Layer skip detected at line {line_num}. "
                               f"Prev layer {last_actual_layer}, current layer {actual_layer_for_headline}. Text: {headline_text}")
                
                layer_text = f"Layer {actual_layer_for_headline}: {headline_text}"

            if current_pattern_type: # Only update last_actual_layer if it was a valid, layered headline
                last_actual_layer = actual_layer_for_headline

            extracted_headlines.append({
                'line_num': line_num,
                'original_text': stripped_line,
                'cleaned_text': headline_text,
                'layer': actual_layer_for_headline, # Store the determined layer
                'formatted_text': layer_text
            })
            
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            if skip_counter > 0:
                f.write(f"**Warning: {skip_counter} layer skips detected during processing.**\n\n")
            for headline_info in extracted_headlines:
                f.write(f"Line {headline_info['line_num']}: {headline_info['formatted_text']}\n")
        
        print(f"Successfully extracted {len(extracted_headlines)} headlines to {output_file}")
        if skip_counter > 0:
            print(f"Warning: {skip_counter} layer skips detected. Check output file and console for details.")
            
    except Exception as e:
        print(f"Error writing output file: {e}")

def is_incomplete_pattern(text, matched_pattern):
    if not matched_pattern: # Should not happen if called after a match
        return False 
    # Basic check: if the matched part is short and the text itself suggests it's incomplete
    # e.g. pattern is r'^[A-Z]\.' but text is just "A"
    if len(matched_pattern) == 1 and text == matched_pattern: # "A" vs "A."
        # Check common patterns where this might be an issue
        if re.match(r'^[A-Z]$', text) or \
           re.match(r'^[a-z]$', text) or \
           re.match(r'^\d+$', text) or \
           re.match(r'^§$', text):
            return True
    return False

def main():
    input_file = "ZPO_processed.md" # Assumes in the same directory as script
    # Construct paths relative to the script's location if needed, or use absolute paths.
    # For now, simple relative path:
    output_file = "ZPO_headlines.md" 

    # Check if input file exists
    if not os.path.exists(input_file):
        # Try looking in a common structure if you are running from a specific project root
        # For example, if script is in 'backend/processing_scripts' and file in 'backend/processing/marker_output/ZPO_temp/'
        # This part is heuristic and might need adjustment based on your project structure
        alt_input_path = os.path.join("..", "marker_output", "ZPO_temp", input_file) # Example path
        if os.path.exists(alt_input_path):
            input_file = alt_input_path
            # Adjust output path accordingly if desired
            output_dir = os.path.join("..", "marker_output", "ZPO_temp")
            if not os.path.exists(output_dir):
                os.makedirs(output_dir) # Create if not exists
            output_file = os.path.join(output_dir, "ZPO_headlines.md")
        else:
            print(f"Error: Input file '{input_file}' (and alternative paths) not found.")
            print("Please make sure the file exists or adjust path in script.")
            return
    
    print(f"Processing headlines from {input_file}...")
    extract_headlines_with_hierarchy(input_file, output_file)
    print(f"Output written to {output_file}")

if __name__ == "__main__":
    main()
```

Key changes in `extract_headlines_with_hierarchy`:
*   `pattern_type_to_established_layer`: Stores the layer number a pattern type achieves when it first defines a new depth.
*   `current_nesting_path_types`: Tracks the sequence of pattern types forming the current nesting. Example: `['section', 'roman']` means we are two levels deep.
*   Layer determination logic:
    *   If a `current_pattern_type` is already in `pattern_type_to_established_layer`, it means we are "returning" to that type's established layer. The `current_nesting_path_types` is trimmed to reflect this.
    *   If it's a new type, it establishes a new layer, extending the `current_nesting_path_types`. Its layer number is `len(current_nesting_path_types) + 1` (before adding itself to the path for this calculation).
*   The `last_actual_layer` and skip detection logic is also revised to work with this new layering.

Please run this updated script. It should now correctly handle the "II. so we are at layer 2 again" scenario as per your narrative. We can then examine its output for the `A.` vs `1.` case and refine further if needed. The pathing in `main()` is also slightly adjusted to be a bit more flexible, assuming the script might not be in the exact same directory as `ZPO_processed.md`. You might need to adjust these paths if your files are elsewhere.

---

_**User**_

thank you but this is not working. Still the same issue. This cannot be that difficult. How is this even possible, if you have implemented the new logic. By the logic I told you to implement the counter for ABC would start at A. and the one for roman numerals would start at I. So the first line is identified as roman numeral, so the first layer is roman numerals. So whenever the code finds the next header to fit the next roman numeral, it now knows it must be layer one. So the next header is II., also roman numerals is looking for II. The code knows that roman numerals is II., so the next header must be layer 1 as well. Etc. This cannot be that hard. Also my file is in backend/processing

---

_**Assistant**_

You're absolutely right - I overcomplicated it. Let's make it simple and direct. For each pattern type, we need to track what's the next expected value. For Roman numerals, we start with "I." and expect "II." next, for letters we start with "A." and expect "B." next, etc.

Here's the simplified version:

```python:headlines.py
import re
import os

class PatternTracker:
    def __init__(self, pattern_type):
        self.pattern_type = pattern_type
        self.layer = None
        
        if pattern_type == 'roman':
            self.sequence = ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.', 'VII.', 'VIII.', 'IX.', 'X.',
                           'XI.', 'XII.', 'XIII.', 'XIV.', 'XV.', 'XVI.', 'XVII.', 'XVIII.', 'XIX.', 'XX.']
            self.current_idx = 0
        elif pattern_type == 'upper_letter':
            self.sequence = [f"{chr(i)}." for i in range(65, 91)]  # A. to Z.
            self.current_idx = 0
        elif pattern_type == 'number':
            self.sequence = [f"{i}." for i in range(1, 101)]  # 1. to 100.
            self.current_idx = 0
        elif pattern_type == 'lower_paren':
            self.sequence = [f"{chr(i)})" for i in range(97, 123)]  # a) to z)
            self.current_idx = 0
    
    def matches_next(self, text):
        if self.current_idx >= len(self.sequence):
            return False
        return text.startswith(self.sequence[self.current_idx])
    
    def advance(self):
        self.current_idx += 1

def extract_headlines_with_hierarchy(input_file, output_file):
    # Initialize pattern trackers
    roman_tracker = PatternTracker('roman')
    letter_tracker = PatternTracker('upper_letter')
    number_tracker = PatternTracker('number')
    lower_paren_tracker = PatternTracker('lower_paren')
    
    # Store all pattern trackers
    pattern_trackers = {
        'roman': roman_tracker,
        'upper_letter': letter_tracker,
        'number': number_tracker,
        'lower_paren': lower_paren_tracker
    }
    
    headlines = []
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        if line.startswith('##'):
            # Clean the headline text
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            # Try to match with next expected value in each pattern
            matched_tracker = None
            
            for tracker in pattern_trackers.values():
                if tracker.matches_next(headline_text):
                    matched_tracker = tracker
                    # If this pattern hasn't been assigned a layer yet, assign it
                    if tracker.layer is None:
                        # Find the next available layer number
                        used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                        if not used_layers:
                            tracker.layer = 1
                        else:
                            tracker.layer = max(used_layers) + 1
                    break
            
            if matched_tracker:
                layer = matched_tracker.layer
                layer_text = f"Layer {layer}: {headline_text}"
                matched_tracker.advance()
            else:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"
            
            headlines.append({
                'line_num': line_num,
                'layer_text': layer_text
            })
    
    # Write output
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            for headline in headlines:
                f.write(f"Line {headline['line_num']}: {headline['layer_text']}\n")
    except Exception as e:
        print(f"Error writing output file: {e}")

def main():
    base_path = "backend/processing/marker_output/ZPO_temp"
    input_file = os.path.join(base_path, "ZPO_processed.md")
    output_file = os.path.join(base_path, "ZPO_headlines.md")
    
    if not os.path.exists(input_file):
        print(f"Error: Input file '{input_file}' not found.")
        return
    
    extract_headlines_with_hierarchy(input_file, output_file)

if __name__ == "__main__":
    main()
```

Key changes:
1. Each pattern type (Roman numerals, letters, etc.) has its own tracker that knows:
   - The exact sequence it expects ("I.", "II.", "III." etc.)
   - What value comes next
   - What layer it represents

2. For Roman numerals:
   - Starts expecting "I."
   - After finding "I.", expects "II."
   - After "II.", expects "III." etc.

3. For letters:
   - Starts expecting "A."
   - After finding "A.", expects "B."
   - After "B.", expects "C." etc.

4. When a headline matches the next expected value of a pattern:
   - If the pattern doesn't have a layer assigned yet, it gets the next available layer number
   - If it does have a layer, it uses that same layer number
   - The pattern advances to expect its next value

This should now correctly handle your example where "I." and "II." are both layer 1 because they're part of the same Roman numeral sequence. Let me know if you need any adjustments!

---

_**User**_

thanks, this works better. Attached my current version. It is in backend/processing/headlines.py. However we now need to make an adjustment for this case. 1., 2., 3. etc. is the third layer here, but as such, can start several times from 1. So the logic here would be that if a header's number doesn't fit any of the next predicted numbers / letters, check if it fits the first number / letter of any pattern

---

_**Assistant**_

Ah yes, good catch! We need to allow patterns to "restart" when we encounter their first value again. Let's modify the PatternTracker class to handle this:

```python:backend/processing/headlines.py
import re
import os

class PatternTracker:
    def __init__(self, pattern_type):
        self.pattern_type = pattern_type
        self.layer = None
        
        if pattern_type == 'roman':
            self.sequence = ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.', 'VII.', 'VIII.', 'IX.', 'X.',
                           'XI.', 'XII.', 'XIII.', 'XIV.', 'XV.', 'XVI.', 'XVII.', 'XVIII.', 'XIX.', 'XX.']
        elif pattern_type == 'upper_letter':
            self.sequence = [f"{chr(i)}." for i in range(65, 91)]  # A. to Z.
        elif pattern_type == 'number':
            self.sequence = [f"{i}." for i in range(1, 101)]  # 1. to 100.
        elif pattern_type == 'lower_paren':
            self.sequence = [f"{chr(i)})" for i in range(97, 123)]  # a) to z)
            
        self.current_idx = 0
        self.first_value = self.sequence[0] if self.sequence else None
    
    def matches_next(self, text):
        """Check if text matches the next expected value in the sequence"""
        if self.current_idx >= len(self.sequence):
            return False
        return text.startswith(self.sequence[self.current_idx])
    
    def matches_first(self, text):
        """Check if text matches the first value in the sequence"""
        return text.startswith(self.first_value)
    
    def advance(self):
        self.current_idx += 1
        
    def reset(self):
        """Reset the tracker to start from the beginning of its sequence"""
        self.current_idx = 1  # Set to 1 because we just found the first value

def extract_headlines_with_hierarchy(input_file, output_file):
    # Initialize pattern trackers
    roman_tracker = PatternTracker('roman')
    letter_tracker = PatternTracker('upper_letter')
    number_tracker = PatternTracker('number')
    lower_paren_tracker = PatternTracker('lower_paren')
    
    # Store all pattern trackers
    pattern_trackers = {
        'roman': roman_tracker,
        'upper_letter': letter_tracker,
        'number': number_tracker,
        'lower_paren': lower_paren_tracker
    }
    
    headlines = []
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
        
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        if line.startswith('##'):
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            matched_tracker = None
            
            # First, try to match with next expected value in each pattern
            for tracker in pattern_trackers.values():
                if tracker.matches_next(headline_text):
                    matched_tracker = tracker
                    if tracker.layer is None:
                        used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                        if not used_layers:
                            tracker.layer = 1
                        else:
                            tracker.layer = max(used_layers) + 1
                    tracker.advance()
                    break
            
            # If no match found, check if it matches the first value of any pattern
            if not matched_tracker:
                for tracker in pattern_trackers.values():
                    if tracker.matches_first(headline_text):
                        matched_tracker = tracker
                        # If this pattern already has a layer, keep using it
                        if tracker.layer is None:
                            used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                            if not used_layers:
                                tracker.layer = 1
                            else:
                                tracker.layer = max(used_layers) + 1
                        tracker.reset()
                        break
            
            if matched_tracker:
                layer = matched_tracker.layer
                layer_text = f"Layer {layer}: {headline_text}"
            else:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"

            headlines.append({
                'line_num': line_num,
                'layer_text': layer_text
            })
            
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            for headline in headlines:
                f.write(f"Line {headline['line_num']}: {headline['layer_text']}\n")
    except Exception as e:
        print(f"Error writing output file: {e}")

def main():
    base_path = "backend/processing"
    input_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_processed.md")
    output_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_headlines.md")
    
    print(f"Processing headlines from {input_file}...")
    extract_headlines_with_hierarchy(input_file, output_file)
    print(f"Output written to {output_file}")

if __name__ == "__main__":
    main()
```

Key changes:
1. Added `matches_first()` method to PatternTracker to check if a text matches the first value in a sequence
2. Added `reset()` method to restart a sequence
3. Modified the main logic to:
   - First try to match the next expected value in each sequence
   - If no match found, try to match the first value of any sequence
   - When matching a first value, keep the pattern's existing layer if it has one
4. Fixed the paths to match your project structure

Now when we encounter "1." after "4.", we'll check if it matches the first value of any pattern. Since it matches the first value of the number pattern and that pattern already has layer 3 assigned, it will continue using layer 3 for the new "1." section.

---

_**User**_

Thanks, works. I would now like to make some improvements to the code. Here is my endgoal: Whenever there is a "layer unclear", this should be more specific, using code logic heuristics, as to why it is unclear. Then a prompt should get constructed, so the circumstances of what makes the layer unclear for a given header, are written into the prompt and then sent to a LLM, for it to determine how to handle that case. This requires several things: The code be more clear for what error is the issue and then to structure data / provide data so that all variables for the LLM prompt can get filled easily and dynamically. Then the llm process has to be built. Let us start with the error handling in the headlines.py code. I have identified three cases that currently need handling (may add more later, these are so far only from my test pdf). The first is an error that is currently not even spotted by the code, where the code accepts the cases that (for example) a fourth layer comes after the second layer. Here, the third layer is already identified, the first three layers are I., 1. and a) but the text extractor has identified a new header A., that comes after a heading of the second layer. But as the third layer is already set, the code (correctly) gives A. the fourth layer. However it is note worthy here that the fourth layer comes after a second layer header, which needs closer inspection. So this is the first error case. This should be handled by function that goes through all headlines in the order as they appear, and checks if there is the case that a layer (or several!) is skipped between to headers, obviously only downwards and forward, so a header of layer 4 followed by a header of layer 2 is obviously fine. Our script currently supports four types of layers which is fine for now,  and based on them and how they were identified, we would need to fill the prompt. This requires a dictionary, where I can determine what to write for each case. I generally need layer_name (in English and German) and sample layer numerals. So for example "Roman numerals (eng) / römische Ziffern (de) / I., II., III." for a roman numerals layer. Then if that is the first layer, the variable first_layer_name gets filled with "Roman numerals" or "römische Ziffern" based on whether the pdf being parsed is English or German. Then first_layer_numerals gets filled with "I., II., III.". This is it for now. I have more variables to fill later, but let us start with that.

---

_**Assistant**_

Great plan! Let's start by implementing better error detection and creating the infrastructure for LLM prompting. Here's the updated `headlines.py` with improved error handling:

```python:backend/processing/headlines.py
import re
import os

class PatternTracker:
    def __init__(self, pattern_type):
        self.pattern_type = pattern_type
        self.layer = None
        
        if pattern_type == 'roman':
            self.sequence = ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.', 'VII.', 'VIII.', 'IX.', 'X.',
                           'XI.', 'XII.', 'XIII.', 'XIV.', 'XV.', 'XVI.', 'XVII.', 'XVIII.', 'XIX.', 'XX.']
        elif pattern_type == 'upper_letter':
            self.sequence = [f"{chr(i)}." for i in range(65, 91)]  # A. to Z.
        elif pattern_type == 'number':
            self.sequence = [f"{i}." for i in range(1, 101)]  # 1. to 100.
        elif pattern_type == 'lower_paren':
            self.sequence = [f"{chr(i)})" for i in range(97, 123)]  # a) to z)
            
        self.current_idx = 0
        self.first_value = self.sequence[0] if self.sequence else None
    
    def matches_next(self, text):
        """Check if text matches the next expected value in the sequence"""
        if self.current_idx >= len(self.sequence):
            return False
        return text.startswith(self.sequence[self.current_idx])
    
    def matches_first(self, text):
        """Check if text matches the first value in the sequence"""
        return text.startswith(self.first_value)
    
    def advance(self):
        self.current_idx += 1
        
    def reset(self):
        """Reset the tracker to start from the beginning of its sequence"""
        self.current_idx = 1  # Set to 1 because we just found the first value

# Pattern metadata for LLM prompting
PATTERN_METADATA = {
    'roman': {
        'name_en': 'Roman numerals',
        'name_de': 'Römische Ziffern',
        'sample_numerals': 'I., II., III.'
    },
    'upper_letter': {
        'name_en': 'Uppercase letters',
        'name_de': 'Großbuchstaben',
        'sample_numerals': 'A., B., C.'
    },
    'number': {
        'name_en': 'Arabic numbers',
        'name_de': 'Arabische Zahlen',
        'sample_numerals': '1., 2., 3.'
    },
    'lower_paren': {
        'name_en': 'Lowercase letters with parentheses',
        'name_de': 'Kleinbuchstaben mit Klammern',
        'sample_numerals': 'a), b), c)'
    }
}

class ErrorCase:
    def __init__(self, error_type, line_num, headline_text, details):
        self.error_type = error_type
        self.line_num = line_num
        self.headline_text = headline_text
        self.details = details

def detect_layer_skips(headlines):
    """
    Detect cases where layers are skipped (e.g., layer 4 after layer 2)
    """
    error_cases = []
    
    for i in range(1, len(headlines)):
        current = headlines[i]
        previous = headlines[i-1]
        
        # Only check numeric layers
        if (isinstance(current['layer'], int) and isinstance(previous['layer'], int)):
            layer_jump = current['layer'] - previous['layer']
            
            # Check for downward skips (layer increases by more than 1)
            if layer_jump > 1:
                skipped_layers = list(range(previous['layer'] + 1, current['layer']))
                
                error_case = ErrorCase(
                    error_type="layer_skip",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'previous_layer': previous['layer'],
                        'current_layer': current['layer'],
                        'skipped_layers': skipped_layers,
                        'previous_headline': previous['cleaned_text'],
                        'previous_line_num': previous['line_num']
                    }
                )
                error_cases.append(error_case)
    
    return error_cases

def detect_language(headlines):
    """
    Simple heuristic to detect if document is German or English
    Based on common German words in headlines
    """
    german_indicators = ['und', 'der', 'die', 'das', 'nach', 'gegen', 'von', 'zur', 'zum', 'Entscheidung', 'Verfahren']
    german_count = 0
    total_words = 0
    
    for headline in headlines:
        if 'cleaned_text' in headline:
            words = headline['cleaned_text'].lower().split()
            total_words += len(words)
            german_count += sum(1 for word in words if word in german_indicators)
    
    # If more than 10% of words are German indicators, consider it German
    return 'de' if total_words > 0 and (german_count / total_words) > 0.1 else 'en'

def get_layer_info(layer_num, pattern_trackers, language):
    """
    Get information about a specific layer for LLM prompting
    """
    for pattern_type, tracker in pattern_trackers.items():
        if tracker.layer == layer_num:
            metadata = PATTERN_METADATA[pattern_type]
            return {
                'layer_name': metadata[f'name_{language}'],
                'layer_numerals': metadata['sample_numerals'],
                'pattern_type': pattern_type
            }
    return None

def create_llm_prompt_data(error_case, headlines, pattern_trackers, language):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown'
        })
    
    return prompt_data

def extract_headlines_with_hierarchy(input_file, output_file):
    # Initialize pattern trackers
    roman_tracker = PatternTracker('roman')
    letter_tracker = PatternTracker('upper_letter')
    number_tracker = PatternTracker('number')
    lower_paren_tracker = PatternTracker('lower_paren')
    
    pattern_trackers = {
        'roman': roman_tracker,
        'upper_letter': letter_tracker,
        'number': number_tracker,
        'lower_paren': lower_paren_tracker
    }
    
    headlines = []
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
        
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        if line.startswith('##'):
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            matched_tracker = None
            
            # First, try to match with next expected value in each pattern
            for tracker in pattern_trackers.values():
                if tracker.matches_next(headline_text):
                    matched_tracker = tracker
                    if tracker.layer is None:
                        used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                        if not used_layers:
                            tracker.layer = 1
                        else:
                            tracker.layer = max(used_layers) + 1
                    tracker.advance()
                    break
            
            # If no match found, check if it matches the first value of any pattern
            if not matched_tracker:
                for tracker in pattern_trackers.values():
                    if tracker.matches_first(headline_text):
                        matched_tracker = tracker
                        if tracker.layer is None:
                            used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                            if not used_layers:
                                tracker.layer = 1
                            else:
                                tracker.layer = max(used_layers) + 1
                        tracker.reset()
                        break
            
            if matched_tracker:
                layer = matched_tracker.layer
                layer_text = f"Layer {layer}: {headline_text}"
            else:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"

            headlines.append({
                'line_num': line_num,
                'layer_text': layer_text,
                'layer': layer,
                'cleaned_text': headline_text,
                'original_text': line
            })
    
    # Detect language
    language = detect_language(headlines)
    print(f"Detected language: {language}")
    
    # Detect errors
    layer_skip_errors = detect_layer_skips(headlines)
    
    # Process errors and create LLM prompt data
    for error in layer_skip_errors:
        prompt_data = create_llm_prompt_data(error, headlines, pattern_trackers, language)
        print(f"Layer skip detected at line {error.line_num}: {error.headline_text}")
        print(f"Prompt data: {prompt_data}")
        # TODO: Send to LLM for resolution
            
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            
            if layer_skip_errors:
                f.write(f"**Warning: {len(layer_skip_errors)} layer skip errors detected**\n\n")
            
            for headline in headlines:
                f.write(f"Line {headline['line_num']}: {headline['layer_text']}\n")
    except Exception as e:
        print(f"Error writing output file: {e}")

def main():
    base_path = "/home/lukas/projects/pdf_mindmap/backend/processing"
    input_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_processed.md")
    output_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_headlines.md")
    
    print(f"Processing headlines from {input_file}...")
    extract_headlines_with_hierarchy(input_file, output_file)
    print(f"Output written to {output_file}")

if __name__ == "__main__":
    main()
```

Key additions:

1. **`PATTERN_METADATA`**: Dictionary with English/German names and sample numerals for each pattern type
2. **`ErrorCase` class**: Structured way to store error information
3. **`detect_layer_skips()`**: Function that finds cases where layers are skipped
4. **`detect_language()`**: Simple heuristic to determine if document is German or English
5. **`get_layer_info()`**: Gets layer metadata for LLM prompting
6. **`create_llm_prompt_data()`**: Creates structured data for LLM prompts
7. **Enhanced headline storage**: Now stores more metadata for error analysis

The script now detects layer skips and prepares structured data for LLM prompting. When you run it, it will print out detected errors and the prompt data that would be sent to the LLM.

What would you like to work on next - adding more error detection cases or building the LLM integration?

---

_**User**_

thanks this is very good already. Now I also need an expected_layer and expected_layer_numerals variable, but this should be simple. So we already have skipped layers and for this /.these layers, add their name and numerals and give the expected variables numbers in case there are several layers skipped. I then need a separate python file, prompt_construction.py that then constructs the prompt, based on the variables. There are several requirements here: First, all the variables need to be filled but also, the correct number of variables need to be added. So we kind of need to have a for-loop for any part of my prompt that is a listing, like "the first header layer is {first_layer_name} ({first_layer_numerals}). The second layer is ..." But elements like "The seoncd layer is ... only get added if they are actually needed. I have this only once though for this case. Then there is a section "At this section, the problem is that the previous header is correctly identified as {layer before problematic layer} ({this layer's numerals}) but then followed by (here then either insert a heading/ headings if there are several) of layer {problematic_layer}: {problematic header 1}, {problematic header 2} etc. (as many problematic headers of the same area there are). Then at the end of the prompt, the text of the entire section should be inserted. The entire section here is the part from the last (and including) correct layer header, to the next correct layer header (so that it spans the incorrect layer headers and what text may come after them).

---

_**Assistant**_

Great! Let's first update the `headlines.py` to add the expected layer information, then create the `prompt_construction.py` file.

First, let's update `headlines.py`:

```python:backend/processing/headlines.py
// ... existing code ...

def create_llm_prompt_data(error_case, headlines, pattern_trackers, language):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        # Get expected layer information for skipped layers
        expected_layers_info = []
        for skipped_layer in details['skipped_layers']:
            layer_info = get_layer_info(skipped_layer, pattern_trackers, language)
            if layer_info:
                expected_layers_info.append({
                    'layer_num': skipped_layer,
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                })
        
        # Find the section text (from last correct header to next correct header)
        section_text = extract_section_text(error_case, headlines)
        
        # Find all problematic headers of the same layer
        problematic_headers = find_problematic_headers_same_layer(error_case, headlines)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown',
            'expected_layers_info': expected_layers_info,
            'section_text': section_text,
            'problematic_headers': problematic_headers
        })
    
    return prompt_data

def extract_section_text(error_case, headlines):
    """
    Extract the text section from the last correct header to the next correct header
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    end_line = headlines[end_index]['line_num'] if end_index < len(headlines) else headlines[-1]['line_num']
    
    return {
        'start_line': start_line,
        'end_line': end_line,
        'start_headline': headlines[start_index]['cleaned_text'] if start_index >= 0 else "",
        'end_headline': headlines[end_index]['cleaned_text'] if end_index < len(headlines) else ""
    }

def find_problematic_headers_same_layer(error_case, headlines):
    """
    Find all headers that have the same problematic layer as the error case
    """
    problematic_layer = None
    error_index = None
    
    # Find the error case in headlines
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            problematic_layer = headline['layer']
            error_index = i
            break
    
    if problematic_layer is None or error_index is None:
        return []
    
    problematic_headers = []
    
    # Look forward from the error case to find all headers of the same problematic layer
    for i in range(error_index, len(headlines)):
        headline = headlines[i]
        if headline['layer'] == problematic_layer:
            problematic_headers.append({
                'line_num': headline['line_num'],
                'text': headline['cleaned_text']
            })
        elif isinstance(headline['layer'], int) and headline['layer'] != problematic_layer:
            # Stop when we hit a different valid layer
            break
    
    return problematic_headers

// ... rest of existing code ...
```

Now let's create the `prompt_construction.py` file:

```python:backend/processing/prompt_construction.py
def construct_layer_skip_prompt(prompt_data):
    """
    Construct a prompt for layer skip error cases
    """
    language = prompt_data['language']
    
    # Start building the prompt
    if language == 'de':
        prompt = "Du bist ein Experte für die Analyse von Dokumentenstrukturen. "
        prompt += "Ich analysiere ein deutsches Dokument und habe ein Problem mit der Hierarchie-Erkennung von Überschriften.\n\n"
        
        # Layer structure explanation
        prompt += "Die Struktur der Überschriften-Ebenen in diesem Dokument ist wie folgt:\n"
        
        # Add layer information dynamically
        all_layers = {}
        all_layers[prompt_data['previous_layer']] = {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
        
        # Add expected layers
        for expected_layer in prompt_data['expected_layers_info']:
            all_layers[expected_layer['layer_num']] = {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
        
        all_layers[prompt_data['current_layer']] = {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
        
        # Sort layers and add them to prompt
        for layer_num in sorted(all_layers.keys()):
            layer_info = all_layers[layer_num]
            if layer_num == 1:
                prompt += f"Die erste Überschriften-Ebene ist {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 2:
                prompt += f"Die zweite Ebene ist {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 3:
                prompt += f"Die dritte Ebene ist {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 4:
                prompt += f"Die vierte Ebene ist {layer_info['name']} ({layer_info['numerals']}).\n"
        
        prompt += "\n"
        
        # Problem description
        prompt += f"Das Problem liegt an dieser Stelle: Die vorherige Überschrift ist korrekt als Ebene {prompt_data['previous_layer']} ({prompt_data['previous_layer_numerals']}) identifiziert, "
        prompt += f"aber dann folgt "
        
        # Add problematic headers
        if len(prompt_data['problematic_headers']) == 1:
            prompt += f"eine Überschrift der Ebene {prompt_data['current_layer']}: {prompt_data['problematic_headers'][0]['text']}"
        else:
            prompt += f"Überschriften der Ebene {prompt_data['current_layer']}: "
            header_texts = [header['text'] for header in prompt_data['problematic_headers']]
            prompt += ", ".join(header_texts)
        
        prompt += ".\n\n"
        
        # Expected layers explanation
        if prompt_data['expected_layers_info']:
            if len(prompt_data['expected_layers_info']) == 1:
                expected = prompt_data['expected_layers_info'][0]
                prompt += f"Erwartet würde Ebene {expected['layer_num']} ({expected['layer_name']}: {expected['layer_numerals']}).\n\n"
            else:
                prompt += "Erwartet würden die Ebenen "
                expected_descriptions = [f"{exp['layer_num']} ({exp['layer_name']}: {exp['layer_numerals']})" 
                                       for exp in prompt_data['expected_layers_info']]
                prompt += " und ".join(expected_descriptions) + ".\n\n"
        
    else:  # English
        prompt = "You are an expert in document structure analysis. "
        prompt += "I am analyzing an English document and have a problem with headline hierarchy detection.\n\n"
        
        # Layer structure explanation
        prompt += "The structure of headline layers in this document is as follows:\n"
        
        # Add layer information dynamically
        all_layers = {}
        all_layers[prompt_data['previous_layer']] = {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
        
        # Add expected layers
        for expected_layer in prompt_data['expected_layers_info']:
            all_layers[expected_layer['layer_num']] = {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
        
        all_layers[prompt_data['current_layer']] = {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
        
        # Sort layers and add them to prompt
        for layer_num in sorted(all_layers.keys()):
            layer_info = all_layers[layer_num]
            if layer_num == 1:
                prompt += f"The first headline layer is {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 2:
                prompt += f"The second layer is {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 3:
                prompt += f"The third layer is {layer_info['name']} ({layer_info['numerals']}).\n"
            elif layer_num == 4:
                prompt += f"The fourth layer is {layer_info['name']} ({layer_info['numerals']}).\n"
        
        prompt += "\n"
        
        # Problem description
        prompt += f"The problem is at this section: The previous header is correctly identified as layer {prompt_data['previous_layer']} ({prompt_data['previous_layer_numerals']}), "
        prompt += f"but then followed by "
        
        # Add problematic headers
        if len(prompt_data['problematic_headers']) == 1:
            prompt += f"a header of layer {prompt_data['current_layer']}: {prompt_data['problematic_headers'][0]['text']}"
        else:
            prompt += f"headers of layer {prompt_data['current_layer']}: "
            header_texts = [header['text'] for header in prompt_data['problematic_headers']]
            prompt += ", ".join(header_texts)
        
        prompt += ".\n\n"
        
        # Expected layers explanation
        if prompt_data['expected_layers_info']:
            if len(prompt_data['expected_layers_info']) == 1:
                expected = prompt_data['expected_layers_info'][0]
                prompt += f"Expected would be layer {expected['layer_num']} ({expected['layer_name']}: {expected['layer_numerals']}).\n\n"
            else:
                prompt += "Expected would be layers "
                expected_descriptions = [f"{exp['layer_num']} ({exp['layer_name']}: {exp['layer_numerals']})" 
                                       for exp in prompt_data['expected_layers_info']]
                prompt += " and ".join(expected_descriptions) + ".\n\n"
    
    # Add section text information
    section = prompt_data['section_text']
    if language == 'de':
        prompt += f"Der relevante Textabschnitt erstreckt sich von Zeile {section['start_line']} bis Zeile {section['end_line']}.\n"
        prompt += f"Startüberschrift: '{section['start_headline']}'\n"
        prompt += f"Endüberschrift: '{section['end_headline']}'\n\n"
        prompt += "Bitte analysiere diesen Fall und gib eine Empfehlung, wie die Hierarchie korrekt zugeordnet werden sollte."
    else:
        prompt += f"The relevant text section spans from line {section['start_line']} to line {section['end_line']}.\n"
        prompt += f"Start headline: '{section['start_headline']}'\n"
        prompt += f"End headline: '{section['end_headline']}'\n\n"
        prompt += "Please analyze this case and provide a recommendation on how the hierarchy should be correctly assigned."
    
    return prompt

def construct_prompt(prompt_data):
    """
    Main function to construct prompts based on error type
    """
    if prompt_data['error_type'] == 'layer_skip':
        return construct_layer_skip_prompt(prompt_data)
    else:
        return f"Unknown error type: {prompt_data['error_type']}"

# Example usage and testing
def test_prompt_construction():
    # Example prompt data for testing
    test_data = {
        'error_type': 'layer_skip',
        'language': 'de',
        'problematic_headline': 'A. Zulässigkeit des Einspruchs',
        'line_number': 218,
        'previous_layer': 2,
        'current_layer': 4,
        'skipped_layers': [3],
        'previous_headline': 'II. Säumnis im Termin oder im Vorverfahren',
        'previous_line_num': 15,
        'previous_layer_name': 'Römische Ziffern',
        'previous_layer_numerals': 'I., II., III.',
        'current_layer_name': 'Großbuchstaben',
        'current_layer_numerals': 'A., B., C.',
        'expected_layers_info': [
            {
                'layer_num': 3,
                'layer_name': 'Arabische Zahlen',
                'layer_numerals': '1., 2., 3.'
            }
        ],
        'section_text': {
            'start_line': 15,
            'end_line': 225,
            'start_headline': 'II. Säumnis im Termin oder im Vorverfahren',
            'end_headline': 'B. Hauptsacheentscheidung'
        },
        'problematic_headers': [
            {'line_num': 218, 'text': 'A. Zulässigkeit des Einspruchs'},
            {'line_num': 225, 'text': 'B. Hauptsacheentscheidung'}
        ]
    }
    
    prompt = construct_prompt(test_data)
    print("Generated prompt:")
    print("=" * 50)
    print(prompt)
    print("=" * 50)

if __name__ == "__main__":
    test_prompt_construction()
```

The key improvements:

1. **Added expected layer information** in `create_llm_prompt_data()` 
2. **Dynamic layer listing** that only adds layers that actually exist
3. **Section text extraction** to provide context around the problematic area
4. **Multiple problematic headers** handling for cases where several headers have the same wrong layer
5. **Language-specific prompts** for both German and English
6. **Flexible structure** that adapts to the number of layers and problematic headers

The prompt will now dynamically construct itself based on what layers exist and how many problematic headers there are, exactly as you requested!

---

_**User**_

thanks really good! However the prompt_construction.py should always start from the first layer, when listing the layers that are already determined (correctly). Also is there a better format / file for me to set the prompt and the elements that are supposed to be dynamic setting this all in a python function file is kind of hard

---

_**Assistant**_

You're absolutely right! Using a template file would be much cleaner and more maintainable. Let's create a template-based system using Jinja2 templates.

First, let's update the `prompt_construction.py` to always start from layer 1 and use templates:

```python:backend/processing/prompt_construction.py
from jinja2 import Template, Environment, FileSystemLoader
import os

def get_all_layers_info(prompt_data, pattern_trackers, language):
    """
    Get information for all layers starting from 1, filling in gaps with 'Unknown'
    """
    all_layers = {}
    max_layer = max(prompt_data['previous_layer'], prompt_data['current_layer'])
    
    # Fill in all layers from 1 to max_layer
    for layer_num in range(1, max_layer + 1):
        layer_info = get_layer_info_by_num(layer_num, pattern_trackers, language, prompt_data)
        all_layers[layer_num] = layer_info
    
    return all_layers

def get_layer_info_by_num(layer_num, pattern_trackers, language, prompt_data):
    """
    Get layer info for a specific layer number, with fallbacks
    """
    # Check if this is the previous layer
    if layer_num == prompt_data['previous_layer']:
        return {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
    
    # Check if this is the current layer
    if layer_num == prompt_data['current_layer']:
        return {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
    
    # Check if this is in expected layers
    for expected_layer in prompt_data['expected_layers_info']:
        if expected_layer['layer_num'] == layer_num:
            return {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
    
    # Default fallback
    return {
        'name': 'Unknown' if language == 'en' else 'Unbekannt',
        'numerals': 'Unknown' if language == 'en' else 'Unbekannt'
    }

def construct_layer_skip_prompt(prompt_data):
    """
    Construct a prompt for layer skip error cases using Jinja2 template
    """
    # Get template directory
    template_dir = os.path.join(os.path.dirname(__file__), 'templates')
    
    # Create Jinja2 environment
    env = Environment(loader=FileSystemLoader(template_dir))
    
    # Load the appropriate template
    if prompt_data['language'] == 'de':
        template = env.get_template('layer_skip_de.txt')
    else:
        template = env.get_template('layer_skip_en.txt')
    
    # Prepare template variables
    # Get all layers info starting from 1
    all_layers = {}
    max_layer = max(prompt_data['previous_layer'], prompt_data['current_layer'])
    
    for layer_num in range(1, max_layer + 1):
        layer_info = get_layer_info_by_num(layer_num, None, prompt_data['language'], prompt_data)
        all_layers[layer_num] = layer_info
    
    # Prepare template context
    context = {
        **prompt_data,
        'all_layers': all_layers,
        'max_layer': max_layer,
        'layer_range': range(1, max_layer + 1)
    }
    
    return template.render(context)

def construct_prompt(prompt_data):
    """
    Main function to construct prompts based on error type
    """
    if prompt_data['error_type'] == 'layer_skip':
        return construct_layer_skip_prompt(prompt_data)
    else:
        return f"Unknown error type: {prompt_data['error_type']}"
```

Now let's create the template files. First, create a `templates` directory in your `backend/processing/` folder:

```txt:backend/processing/templates/layer_skip_de.txt
Du bist ein Experte für die Analyse von Dokumentenstrukturen. Ich analysiere ein deutsches Dokument und habe ein Problem mit der Hierarchie-Erkennung von Überschriften.

Die Struktur der Überschriften-Ebenen in diesem Dokument ist wie folgt:
{% for layer_num in layer_range -%}
{% set layer_info = all_layers[layer_num] -%}
{% if layer_num == 1 -%}
Die erste Überschriften-Ebene ist {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 2 -%}
Die zweite Ebene ist {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 3 -%}
Die dritte Ebene ist {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 4 -%}
Die vierte Ebene ist {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 5 -%}
Die fünfte Ebene ist {{ layer_info.name }} ({{ layer_info.numerals }}).
{% endif -%}
{% endfor %}

Das Problem liegt an dieser Stelle: Die vorherige Überschrift ist korrekt als Ebene {{ previous_layer }} ({{ previous_layer_numerals }}) identifiziert, aber dann folgt {% if problematic_headers|length == 1 -%}
eine Überschrift der Ebene {{ current_layer }}: {{ problematic_headers[0].text }}
{%- else -%}
Überschriften der Ebene {{ current_layer }}: {{ problematic_headers | map(attribute='text') | join(', ') }}
{%- endif %}.

{% if expected_layers_info|length > 0 -%}
{% if expected_layers_info|length == 1 -%}
{% set expected = expected_layers_info[0] -%}
Erwartet würde Ebene {{ expected.layer_num }} ({{ expected.layer_name }}: {{ expected.layer_numerals }}).
{% else -%}
Erwartet würden die Ebenen {% for exp in expected_layers_info -%}
{{ exp.layer_num }} ({{ exp.layer_name }}: {{ exp.layer_numerals }})
{%- if not loop.last %} und {% endif -%}
{%- endfor %}.
{% endif -%}
{% endif %}

Der relevante Textabschnitt erstreckt sich von Zeile {{ section_text.start_line }} bis Zeile {{ section_text.end_line }}.
Startüberschrift: '{{ section_text.start_headline }}'
Endüberschrift: '{{ section_text.end_headline }}'

Bitte analysiere diesen Fall und gib eine Empfehlung, wie die Hierarchie korrekt zugeordnet werden sollte. Berücksichtige dabei:
1. Die etablierte Struktur der Überschriften-Ebenen
2. Den Kontext der umgebenden Überschriften
3. Die logische Struktur des Dokuments

Antworte mit einer klaren Empfehlung und Begründung.
```

```txt:backend/processing/templates/layer_skip_en.txt
You are an expert in document structure analysis. I am analyzing an English document and have a problem with headline hierarchy detection.

The structure of headline layers in this document is as follows:
{% for layer_num in layer_range -%}
{% set layer_info = all_layers[layer_num] -%}
{% if layer_num == 1 -%}
The first headline layer is {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 2 -%}
The second layer is {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 3 -%}
The third layer is {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 4 -%}
The fourth layer is {{ layer_info.name }} ({{ layer_info.numerals }}).
{% elif layer_num == 5 -%}
The fifth layer is {{ layer_info.name }} ({{ layer_info.numerals }}).
{% endif -%}
{% endfor %}

The problem is at this section: The previous header is correctly identified as layer {{ previous_layer }} ({{ previous_layer_numerals }}), but then followed by {% if problematic_headers|length == 1 -%}
a header of layer {{ current_layer }}: {{ problematic_headers[0].text }}
{%- else -%}
headers of layer {{ current_layer }}: {{ problematic_headers | map(attribute='text') | join(', ') }}
{%- endif %}.

{% if expected_layers_info|length > 0 -%}
{% if expected_layers_info|length == 1 -%}
{% set expected = expected_layers_info[0] -%}
Expected would be layer {{ expected.layer_num }} ({{ expected.layer_name }}: {{ expected.layer_numerals }}).
{% else -%}
Expected would be layers {% for exp in expected_layers_info -%}
{{ exp.layer_num }} ({{ exp.layer_name }}: {{ exp.layer_numerals }})
{%- if not loop.last %} and {% endif -%}
{%- endfor %}.
{% endif -%}
{% endif %}

The relevant text section spans from line {{ section_text.start_line }} to line {{ section_text.end_line }}.
Start headline: '{{ section_text.start_headline }}'
End headline: '{{ section_text.end_headline }}'

Please analyze this case and provide a recommendation on how the hierarchy should be correctly assigned. Consider:
1. The established structure of headline layers
2. The context of surrounding headlines  
3. The logical structure of the document

Respond with a clear recommendation and reasoning.
```

You'll also need to install Jinja2 if you haven't already:

```bash
pip install Jinja2
```

This template-based approach offers several advantages:

1. **Separation of concerns**: Logic is in Python, content is in templates
2. **Easy editing**: You can modify prompts without touching Python code
3. **Dynamic content**: Templates handle loops, conditionals, and variable substitution cleanly
4. **Maintainability**: Much easier to read and modify the prompt structure
5. **Multilingual**: Easy to maintain different language versions

The templates now:
- Always start from layer 1 and go up to the maximum layer needed
- Handle dynamic lists properly with Jinja2 loops
- Include proper conditional logic for singular/plural cases
- Are much more readable and editable than Python string concatenation

Would you like me to add any other template features or adjust the prompt content?

---

_**User**_

Please adjust this text, so that it doesn't have start and end headline and what lines this spans, but the entire text section, but no line numbers etc. We can obviously no longer construct a separate test case anymore then, but this is fine, make sure the prompt_construction.py file gets called from the headlines.py file, when the error case happens.

---

_**Assistant**_

I'll update the code to include the actual text content instead of just line numbers and references. Let's modify both files:

First, let's update `headlines.py` to extract the actual text content and call the prompt construction:

```python:backend/processing/headlines.py
// ... existing code ...

def extract_section_text(error_case, headlines, input_file):
    """
    Extract the actual text content from the last correct header to the next correct header
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    end_line = headlines[end_index]['line_num'] if end_index < len(headlines) else None
    
    # Read the actual text content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Extract the relevant section
        if end_line:
            section_lines = lines[start_line-1:end_line-1]  # -1 because line numbers are 1-based
        else:
            section_lines = lines[start_line-1:]
        
        section_text = ''.join(section_lines).strip()
        
    except Exception as e:
        print(f"Error reading section text: {e}")
        section_text = "Error reading section text"
    
    return section_text

def create_llm_prompt_data(error_case, headlines, pattern_trackers, language, input_file):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        # Get expected layer information for skipped layers
        expected_layers_info = []
        for skipped_layer in details['skipped_layers']:
            layer_info = get_layer_info(skipped_layer, pattern_trackers, language)
            if layer_info:
                expected_layers_info.append({
                    'layer_num': skipped_layer,
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                })
        
        # Find the section text (actual content)
        section_text = extract_section_text(error_case, headlines, input_file)
        
        # Find all problematic headers of the same layer
        problematic_headers = find_problematic_headers_same_layer(error_case, headlines)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown',
            'expected_layers_info': expected_layers_info,
            'section_text': section_text,
            'problematic_headers': problematic_headers
        })
    
    return prompt_data

def extract_headlines_with_hierarchy(input_file, output_file):
    # ... existing code until error processing ...
    
    # Detect language
    language = detect_language(headlines)
    print(f"Detected language: {language}")
    
    # Detect errors
    layer_skip_errors = detect_layer_skips(headlines)
    
    # Process errors and create LLM prompt data
    for error in layer_skip_errors:
        prompt_data = create_llm_prompt_data(error, headlines, pattern_trackers, language, input_file)
        print(f"Layer skip detected at line {error.line_num}: {error.headline_text}")
        
        # Import and call prompt construction
        from prompt_construction import construct_prompt
        generated_prompt = construct_prompt(prompt_data)
        
        print("Generated LLM Prompt:")
        print("=" * 60)
        print(generated_prompt)
        print("=" * 60)
        print()
        
        # TODO: Send to LLM for resolution
    
    # ... rest of existing code ...
```

Now let's update the template files to include the actual text content:

```txt:backend/processing/templates/layer_skip_de.txt
Du bist Teil eines Korrektursystems für die Korrektur von extrahiertem Text. Bei dem nachfolgenden Stück Text hat das Programm, dass die Überschriftenebenen festlegt, eine Unklarheit gefunden.

Es wurde bislang festgestellt, dass die
{% for layer_num in layer_range -%}
{% set layer_info = all_layers[layer_num] -%}
{% if layer_num == 1 -%}
erste Überschriften-Ebene {{ layer_info.name }} ({{ layer_info.numerals }}) sind{% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 2 -%}
zweite Ebene {{ layer_info.name }} ({{ layer_info.numerals }}) sind{% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 3 -%}
dritte Ebene {{ layer_info.name }} ({{ layer_info.numerals }}) sind{% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 4 -%}
vierte Ebene {{ layer_info.name }} ({{ layer_info.numerals }}) sind{% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 5 -%}
fünfte Ebene {{ layer_info.name }} ({{ layer_info.numerals }}) sind{% if not loop.last %},{% else %}.{% endif %}
{% endif -%}
{% endfor %}

Das Problem liegt an dieser Stelle: Die vorherige Überschrift ist korrekt als Ebene {{ previous_layer }} ({{ previous_layer_numerals }}) identifiziert, aber dann folgt {% if problematic_headers|length == 1 -%}
eine Überschrift der Ebene {{ current_layer }}: "{{ problematic_headers[0].text }}"
{%- else -%}
Überschriften der Ebene {{ current_layer }}: {% for header in problematic_headers %}"{{ header.text }}"{% if not loop.last %}, {% endif %}{% endfor %}
{%- endif %}.

{% if expected_layers_info|length > 0 -%}
{% if expected_layers_info|length == 1 -%}
{% set expected = expected_layers_info[0] -%}
Erwartet würde Ebene {{ expected.layer_num }} ({{ expected.layer_name }}: {{ expected.layer_numerals }}).
{% else -%}
Erwartet würden die Ebenen {% for exp in expected_layers_info -%}
{{ exp.layer_num }} ({{ exp.layer_name }}: {{ exp.layer_numerals }})
{%- if not loop.last %} und {% endif -%}
{%- endfor %}.
{% endif -%}
{% endif %}

Hier ist der relevante Textabschnitt:

---
{{ section_text }}
---

Bitte schau dir den relevanten Kontext an und identifiziere in einem ersten Schritt, ob es sich bei den identifizierten Überschriften überhaupt um Überschriften handelt. Entscheide dann, ob diese Überschriften eine Gliederungsebene des Dokuments darstellen, oder nur bspw. nur Teil eines Beispiels sind.

Im juristischen Bereich wird besonders bei Prüfungsschemata eine Nummerierung vorgenommen. Diese kann dann die Software-Logik, die die Überschriftenebenen identifizieren soll, durcheinander bringen.

Antworte mit einer klaren Empfehlung und Begründung.
```

```txt:backend/processing/templates/layer_skip_en.txt
You are part of a correction system for extracted text. The program that determines headline levels has found an ambiguity in the following piece of text.

It has been determined so far that the
{% for layer_num in layer_range -%}
{% set layer_info = all_layers[layer_num] -%}
{% if layer_num == 1 -%}
first headline layer is {{ layer_info.name }} ({{ layer_info.numerals }}){% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 2 -%}
second layer is {{ layer_info.name }} ({{ layer_info.numerals }}){% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 3 -%}
third layer is {{ layer_info.name }} ({{ layer_info.numerals }}){% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 4 -%}
fourth layer is {{ layer_info.name }} ({{ layer_info.numerals }}){% if not loop.last %},{% else %}.{% endif %}
{% elif layer_num == 5 -%}
fifth layer is {{ layer_info.name }} ({{ layer_info.numerals }}){% if not loop.last %},{% else %}.{% endif %}
{% endif -%}
{% endfor %}

The problem is at this section: The previous header is correctly identified as layer {{ previous_layer }} ({{ previous_layer_numerals }}), but then followed by {% if problematic_headers|length == 1 -%}
a header of layer {{ current_layer }}: "{{ problematic_headers[0].text }}"
{%- else -%}
headers of layer {{ current_layer }}: {% for header in problematic_headers %}"{{ header.text }}"{% if not loop.last %}, {% endif %}{% endfor %}
{%- endif %}.

{% if expected_layers_info|length > 0 -%}
{% if expected_layers_info|length == 1 -%}
{% set expected = expected_layers_info[0] -%}
Expected would be layer {{ expected.layer_num }} ({{ expected.layer_name }}: {{ expected.layer_numerals }}).
{% else -%}
Expected would be layers {% for exp in expected_layers_info -%}
{{ exp.layer_num }} ({{ exp.layer_name }}: {{ exp.layer_numerals }})
{%- if not loop.last %} and {% endif -%}
{%- endfor %}.
{% endif -%}
{% endif %}

Here is the relevant text section:

---
{{ section_text }}
---

Please look at the relevant context and identify in a first step whether the identified headlines are actually headlines at all. Then decide whether these headlines represent a structural level of the document, or are just part of an example, for instance.

In the legal field, especially in examination schemes, numbering is often used. This can then confuse the software logic that is supposed to identify the headline levels.

Respond with a clear recommendation and reasoning.
```

And update the `prompt_construction.py` to remove the test function since we're now calling it from `headlines.py`:

```python:backend/processing/prompt_construction.py
from jinja2 import Template, Environment, FileSystemLoader
import os

def get_layer_info_by_num(layer_num, pattern_trackers, language, prompt_data):
    """
    Get layer info for a specific layer number, with fallbacks
    """
    # Check if this is the previous layer
    if layer_num == prompt_data['previous_layer']:
        return {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
    
    # Check if this is the current layer
    if layer_num == prompt_data['current_layer']:
        return {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
    
    # Check if this is in expected layers
    for expected_layer in prompt_data['expected_layers_info']:
        if expected_layer['layer_num'] == layer_num:
            return {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
    
    # Default fallback
    return {
        'name': 'Unknown' if language == 'en' else 'Unbekannt',
        'numerals': 'Unknown' if language == 'en' else 'Unbekannt'
    }

def construct_layer_skip_prompt(prompt_data):
    """
    Construct a prompt for layer skip error cases using Jinja2 template
    """
    # Get template directory
    template_dir = os.path.join(os.path.dirname(__file__), 'templates')
    
    # Create Jinja2 environment
    env = Environment(loader=FileSystemLoader(template_dir))
    
    # Load the appropriate template
    if prompt_data['language'] == 'de':
        template = env.get_template('layer_skip_de.txt')
    else:
        template = env.get_template('layer_skip_en.txt')
    
    # Prepare template variables
    # Get all layers info starting from 1
    all_layers = {}
    max_layer = max(prompt_data['previous_layer'], prompt_data['current_layer'])
    
    for layer_num in range(1, max_layer + 1):
        layer_info = get_layer_info_by_num(layer_num, None, prompt_data['language'], prompt_data)
        all_layers[layer_num] = layer_info
    
    # Prepare template context
    context = {
        **prompt_data,
        'all_layers': all_layers,
        'max_layer': max_layer,
        'layer_range': range(1, max_layer + 1)
    }
    
    return template.render(context)

def construct_prompt(prompt_data):
    """
    Main function to construct prompts based on error type
    """
    if prompt_data['error_type'] == 'layer_skip':
        return construct_layer_skip_prompt(prompt_data)
    else:
        return f"Unknown error type: {prompt_data['error_type']}"
```

Now when you run `headlines.py`, it will:

1. Detect layer skip errors
2. Extract the actual text content from the problematic section
3. Generate and print the complete LLM prompt with the real text content
4. The prompt will include the full context that the LLM needs to make a decision

The prompt now contains the actual text section instead of just line references, making it much more useful for LLM analysis.

---

_**User**_

thanks, where can I view the constructed prompt now?

---

_**Assistant**_

You need to make a couple of updates to see the constructed prompt. Currently, the `headlines.py` file has the logic to create the prompt data but doesn't actually call the prompt construction function. Let me show you what needs to be updated:

```python:backend/processing/headlines.py
// ... existing code ...

def extract_section_text(error_case, headlines, input_file):
    """
    Extract the actual text content from the last correct header to the next correct header
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    end_line = headlines[end_index]['line_num'] if end_index < len(headlines) else None
    
    # Read the actual text content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Extract the relevant section
        if end_line:
            section_lines = lines[start_line-1:end_line-1]  # -1 because line numbers are 1-based
        else:
            section_lines = lines[start_line-1:]
        
        section_text = ''.join(section_lines).strip()
        
    except Exception as e:
        print(f"Error reading section text: {e}")
        section_text = "Error reading section text"
    
    return section_text

def create_llm_prompt_data(error_case, headlines, pattern_trackers, language, input_file):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        # Get expected layer information for skipped layers
        expected_layers_info = []
        for skipped_layer in details['skipped_layers']:
            layer_info = get_layer_info(skipped_layer, pattern_trackers, language)
            if layer_info:
                expected_layers_info.append({
                    'layer_num': skipped_layer,
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                })
        
        # Find the section text (actual content)
        section_text = extract_section_text(error_case, headlines, input_file)
        
        # Find all problematic headers of the same layer
        problematic_headers = find_problematic_headers_same_layer(error_case, headlines)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown',
            'expected_layers_info': expected_layers_info,
            'section_text': section_text,
            'problematic_headers': problematic_headers
        })
    
    return prompt_data

def extract_headlines_with_hierarchy(input_file, output_file):
    # ... existing code until error processing ...
    
    # Detect language
    language = detect_language(headlines)
    print(f"Detected language: {language}")
    
    # Detect errors
    layer_skip_errors = detect_layer_skips(headlines)
    
    # Process errors and create LLM prompt data
    for error in layer_skip_errors:
        prompt_data = create_llm_prompt_data(error, headlines, pattern_trackers, language, input_file)
        print(f"Layer skip detected at line {error.line_num}: {error.headline_text}")
        
        # Import and call prompt construction
        from prompt_construction import construct_prompt
        generated_prompt = construct_prompt(prompt_data)
        
        print("\n" + "="*80)
        print("GENERATED LLM PROMPT:")
        print("="*80)
        print(generated_prompt)
        print("="*80 + "\n")
        
        # TODO: Send to LLM for resolution
    
    # ... rest of existing code ...
```

After making this update, when you run the `headlines.py` script:

```bash
cd backend/processing
python headlines.py
```

You will see:
1. The normal processing output
2. Any detected layer skip errors
3. **The full constructed prompt printed to the console** between the `===` lines

The prompt will include:
- The detected layer structure
- The problematic headers
- The full text section with context
- Instructions for the LLM in the appropriate language (German or English)

The prompt will be displayed in the terminal whenever a layer skip error is detected during processing.

---

_**User**_

thanks, works fine. Something is not working with the first layer though yet, can you please look at the files again?  

---

_**Assistant**_

Looking at the output, I can see the issue. The first layer is showing as "Unbekannt (Unbekannt)" instead of the actual pattern information. The problem is in the `get_layer_info_by_num` function in `prompt_construction.py` - it's not properly finding the layer information for layer 1.

Let's fix this by updating the `prompt_construction.py` file:

```python:backend/processing/prompt_construction.py
from jinja2 import Template, Environment, FileSystemLoader
import os

def get_layer_info_by_num(layer_num, pattern_trackers, language, prompt_data):
    """
    Get layer info for a specific layer number, with fallbacks
    """
    # Check if this is the previous layer
    if layer_num == prompt_data['previous_layer']:
        return {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
    
    # Check if this is the current layer
    if layer_num == prompt_data['current_layer']:
        return {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
    
    # Check if this is in expected layers
    for expected_layer in prompt_data['expected_layers_info']:
        if expected_layer['layer_num'] == layer_num:
            return {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
    
    # If we still don't have info, we need to get it from the pattern_trackers
    # This requires us to pass the pattern_trackers from headlines.py
    # For now, return a more descriptive unknown
    return {
        'name': 'Unknown' if language == 'en' else 'Unbekannt',
        'numerals': 'Unknown' if language == 'en' else 'Unbekannt'
    }

def construct_layer_skip_prompt(prompt_data):
    """
    Construct a prompt for layer skip error cases using Jinja2 template
    """
    # Get template directory
    template_dir = os.path.join(os.path.dirname(__file__), 'templates')
    
    # Create Jinja2 environment
    env = Environment(loader=FileSystemLoader(template_dir))
    
    # Load the appropriate template
    if prompt_data['language'] == 'de':
        template = env.get_template('layer_skip_de.txt')
    else:
        template = env.get_template('layer_skip_en.txt')
    
    # Prepare template variables
    # Get all layers info starting from 1
    all_layers = {}
    max_layer = max(prompt_data['previous_layer'], prompt_data['current_layer'])
    
    for layer_num in range(1, max_layer + 1):
        layer_info = get_layer_info_by_num(layer_num, None, prompt_data['language'], prompt_data)
        all_layers[layer_num] = layer_info
    
    # Prepare template context
    context = {
        **prompt_data,
        'all_layers': all_layers,
        'max_layer': max_layer,
        'layer_range': range(1, max_layer + 1)
    }
    
    return template.render(context)

def construct_prompt(prompt_data):
    """
    Main function to construct prompts based on error type
    """
    if prompt_data['error_type'] == 'layer_skip':
        return construct_layer_skip_prompt(prompt_data)
    else:
        return f"Unknown error type: {prompt_data['error_type']}"
```

But the real issue is that we need to pass more complete layer information from `headlines.py`. Let's update the `create_llm_prompt_data` function to include information about ALL layers:

```python:backend/processing/headlines.py
// ... existing code ...

def create_llm_prompt_data(error_case, headlines, pattern_trackers, language, input_file):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        # Get expected layer information for skipped layers
        expected_layers_info = []
        for skipped_layer in details['skipped_layers']:
            layer_info = get_layer_info(skipped_layer, pattern_trackers, language)
            if layer_info:
                expected_layers_info.append({
                    'layer_num': skipped_layer,
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                })
        
        # Get ALL layer information for complete context
        all_layers_info = {}
        max_layer = max(details['previous_layer'], details['current_layer'])
        for layer_num in range(1, max_layer + 1):
            layer_info = get_layer_info(layer_num, pattern_trackers, language)
            if layer_info:
                all_layers_info[layer_num] = {
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                }
        
        # Find the section text (actual content)
        section_text = extract_section_text(error_case, headlines, input_file)
        
        # Find all problematic headers of the same layer
        problematic_headers = find_problematic_headers_same_layer(error_case, headlines)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown',
            'expected_layers_info': expected_layers_info,
            'all_layers_info': all_layers_info,
            'section_text': section_text,
            'problematic_headers': problematic_headers
        })
    
    return prompt_data

// ... rest of existing code ...
```

And update the `prompt_construction.py` to use this complete layer information:

```python:backend/processing/prompt_construction.py
from jinja2 import Template, Environment, FileSystemLoader
import os

def get_layer_info_by_num(layer_num, pattern_trackers, language, prompt_data):
    """
    Get layer info for a specific layer number, with fallbacks
    """
    # First check if we have complete layer info
    if 'all_layers_info' in prompt_data and layer_num in prompt_data['all_layers_info']:
        layer_info = prompt_data['all_layers_info'][layer_num]
        return {
            'name': layer_info['layer_name'],
            'numerals': layer_info['layer_numerals']
        }
    
    # Check if this is the previous layer
    if layer_num == prompt_data['previous_layer']:
        return {
            'name': prompt_data['previous_layer_name'],
            'numerals': prompt_data['previous_layer_numerals']
        }
    
    # Check if this is the current layer
    if layer_num == prompt_data['current_layer']:
        return {
            'name': prompt_data['current_layer_name'],
            'numerals': prompt_data['current_layer_numerals']
        }
    
    # Check if this is in expected layers
    for expected_layer in prompt_data['expected_layers_info']:
        if expected_layer['layer_num'] == layer_num:
            return {
                'name': expected_layer['layer_name'],
                'numerals': expected_layer['layer_numerals']
            }
    
    # Default fallback
    return {
        'name': 'Unknown' if language == 'en' else 'Unbekannt',
        'numerals': 'Unknown' if language == 'en' else 'Unbekannt'
    }

def construct_layer_skip_prompt(prompt_data):
    """
    Construct a prompt for layer skip error cases using Jinja2 template
    """
    # Get template directory
    template_dir = os.path.join(os.path.dirname(__file__), 'templates')
    
    # Create Jinja2 environment
    env = Environment(loader=FileSystemLoader(template_dir))
    
    # Load the appropriate template
    if prompt_data['language'] == 'de':
        template = env.get_template('layer_skip_de.txt')
    else:
        template = env.get_template('layer_skip_en.txt')
    
    # Prepare template variables
    # Get all layers info starting from 1
    all_layers = {}
    max_layer = max(prompt_data['previous_layer'], prompt_data['current_layer'])
    
    for layer_num in range(1, max_layer + 1):
        layer_info = get_layer_info_by_num(layer_num, None, prompt_data['language'], prompt_data)
        all_layers[layer_num] = layer_info
    
    # Prepare template context
    context = {
        **prompt_data,
        'all_layers': all_layers,
        'max_layer': max_layer,
        'layer_range': range(1, max_layer + 1)
    }
    
    return template.render(context)

def construct_prompt(prompt_data):
    """
    Main function to construct prompts based on error type
    """
    if prompt_data['error_type'] == 'layer_skip':
        return construct_layer_skip_prompt(prompt_data)
    else:
        return f"Unknown error type: {prompt_data['error_type']}"
```

This should now properly show the first layer information instead of "Unbekannt". The key changes are:

1. In `headlines.py`: Added `all_layers_info` to the prompt data that contains complete information about all layers
2. In `prompt_construction.py`: Updated `get_layer_info_by_num` to first check the complete layer info before falling back to individual layer checks

Now when you run the script, it should properly display the first layer information in the generated prompt.

---

_**User**_

thanks, works fine! Can you increase the section text, so it includes the next header that is correct as well?

---

_**Assistant**_

Sure! Let's modify the `extract_section_text` function in `headlines.py` to include the next correct header as well:

```python:backend/processing/headlines.py
// ... existing code ...

def extract_section_text(error_case, headlines, input_file):
    """
    Extract the actual text content from the last correct header to the next correct header (inclusive)
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    
    # Include the next correct header by extending to the line AFTER it
    if end_index < len(headlines):
        # If there's a header after the next correct one, go up to that line
        if end_index + 1 < len(headlines):
            end_line = headlines[end_index + 1]['line_num']
        else:
            # If this is the last header, include some lines after it
            end_line = headlines[end_index]['line_num'] + 10  # Include 10 lines after the last header
    else:
        end_line = None
    
    # Read the actual text content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Extract the relevant section
        if end_line and end_line <= len(lines):
            section_lines = lines[start_line-1:end_line-1]  # -1 because line numbers are 1-based
        elif end_line:
            # If end_line exceeds file length, just go to end of file
            section_lines = lines[start_line-1:]
        else:
            section_lines = lines[start_line-1:]
        
        section_text = ''.join(section_lines).strip()
        
    except Exception as e:
        print(f"Error reading section text: {e}")
        section_text = "Error reading section text"
    
    return section_text

// ... rest of existing code ...
```

The key changes:

1. **Extended end range**: Instead of stopping right before the next correct header, we now include it and extend beyond it
2. **Smart boundary handling**: 
   - If there's another header after the next correct one, we include text up to that next header
   - If it's the last header in the document, we include 10 additional lines after it
   - If we exceed the file length, we just go to the end of the file

This will give the LLM more context by showing:
- The last correct header before the problem
- All the problematic headers and their content
- The next correct header that comes after the problematic section
- Some additional content after that correct header to provide full context

This should help the LLM better understand the document structure and make more informed decisions about how to handle the problematic headers.

---

_**User**_

thanks, works fine. Now there are two other cases we need to handle in headlines.py, duplicate headers and headers that have no numerals or letter. Here is an example case for a duplicate, note that one has a number at the end, this is due to a page number being incorrectly parsed as part of the header, so we cannot rely on full match here. Ideally, we would by default remove the longer header. Then the second case is when the layer is unclear, like here Line 268: Layer unclear: Empfehlungen zur vertiefenden Lektüre:, in that case assign the same layer as the header before, however make a note or something that this header was not defined through having its own numeral. 

---

_**Assistant**_

Great! Let's add these two new error detection and handling cases to `headlines.py`. I'll add functions to detect duplicates and handle unclear headers:

```python:backend/processing/headlines.py
// ... existing code ...

def detect_duplicate_headers(headlines):
    """
    Detect duplicate headers, especially those with page numbers incorrectly parsed
    """
    error_cases = []
    
    for i in range(len(headlines)):
        current = headlines[i]
        
        # Skip if current header is already marked for removal
        if current.get('marked_for_removal', False):
            continue
            
        for j in range(i + 1, len(headlines)):
            other = headlines[j]
            
            # Skip if other header is already marked for removal
            if other.get('marked_for_removal', False):
                continue
            
            current_text = current['cleaned_text'].strip()
            other_text = other['cleaned_text'].strip()
            
            # Check if one header is a substring of another (indicating page number issue)
            if current_text in other_text or other_text in current_text:
                # Mark the longer one for removal (it likely has the page number)
                if len(current_text) > len(other_text):
                    current['marked_for_removal'] = True
                    error_case = ErrorCase(
                        error_type="duplicate_header",
                        line_num=current['line_num'],
                        headline_text=current['cleaned_text'],
                        details={
                            'duplicate_of_line': other['line_num'],
                            'duplicate_of_text': other['cleaned_text'],
                            'action': 'remove_longer'
                        }
                    )
                else:
                    other['marked_for_removal'] = True
                    error_case = ErrorCase(
                        error_type="duplicate_header",
                        line_num=other['line_num'],
                        headline_text=other['cleaned_text'],
                        details={
                            'duplicate_of_line': current['line_num'],
                            'duplicate_of_text': current['cleaned_text'],
                            'action': 'remove_longer'
                        }
                    )
                
                error_cases.append(error_case)
                break  # Move to next header once we found a duplicate
    
    return error_cases

def handle_unclear_headers(headlines):
    """
    Assign unclear headers the same layer as the previous header
    """
    error_cases = []
    
    for i in range(len(headlines)):
        current = headlines[i]
        
        # Skip headers marked for removal
        if current.get('marked_for_removal', False):
            continue
            
        if current['layer'] == "unclear":
            # Find the previous valid header
            previous_layer = None
            for j in range(i - 1, -1, -1):
                prev_header = headlines[j]
                if (not prev_header.get('marked_for_removal', False) and 
                    isinstance(prev_header['layer'], int)):
                    previous_layer = prev_header['layer']
                    break
            
            if previous_layer is not None:
                # Assign the same layer as previous header
                current['layer'] = previous_layer
                current['layer_text'] = f"Layer {previous_layer}: {current['cleaned_text']} (inherited layer - no numeral pattern)"
                current['inherited_layer'] = True
                
                error_case = ErrorCase(
                    error_type="unclear_header_assigned",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'assigned_layer': previous_layer,
                        'reason': 'no_numeral_pattern'
                    }
                )
                error_cases.append(error_case)
            else:
                # No previous layer found, assign layer 1 as fallback
                current['layer'] = 1
                current['layer_text'] = f"Layer 1: {current['cleaned_text']} (fallback layer - no numeral pattern)"
                current['inherited_layer'] = True
                
                error_case = ErrorCase(
                    error_type="unclear_header_assigned",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'assigned_layer': 1,
                        'reason': 'no_numeral_pattern_fallback'
                    }
                )
                error_cases.append(error_case)
    
    return error_cases

def remove_marked_headers(headlines):
    """
    Remove headers that have been marked for removal
    """
    return [h for h in headlines if not h.get('marked_for_removal', False)]

def extract_headlines_with_hierarchy(input_file, output_file):
    # Initialize pattern trackers
    roman_tracker = PatternTracker('roman')
    letter_tracker = PatternTracker('upper_letter')
    number_tracker = PatternTracker('number')
    lower_paren_tracker = PatternTracker('lower_paren')
    
    pattern_trackers = {
        'roman': roman_tracker,
        'upper_letter': letter_tracker,
        'number': number_tracker,
        'lower_paren': lower_paren_tracker
    }
    
    headlines = []
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
        
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        if line.startswith('##'):
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            matched_tracker = None
            
            # First, try to match with next expected value in each pattern
            for tracker in pattern_trackers.values():
                if tracker.matches_next(headline_text):
                    matched_tracker = tracker
                    if tracker.layer is None:
                        used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                        if not used_layers:
                            tracker.layer = 1
                        else:
                            tracker.layer = max(used_layers) + 1
                    tracker.advance()
                    break
            
            # If no match found, check if it matches the first value of any pattern
            if not matched_tracker:
                for tracker in pattern_trackers.values():
                    if tracker.matches_first(headline_text):
                        matched_tracker = tracker
                        if tracker.layer is None:
                            used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                            if not used_layers:
                                tracker.layer = 1
                            else:
                                tracker.layer = max(used_layers) + 1
                        tracker.reset()
                        break
            
            if matched_tracker:
                layer = matched_tracker.layer
                layer_text = f"Layer {layer}: {headline_text}"
            else:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"

            headlines.append({
                'line_num': line_num,
                'layer_text': layer_text,
                'layer': layer,
                'cleaned_text': headline_text,
                'original_text': line,
                'inherited_layer': False
            })
    
    # Detect language
    language = detect_language(headlines)
    print(f"Detected language: {language}")
    
    # Handle duplicates first
    duplicate_errors = detect_duplicate_headers(headlines)
    if duplicate_errors:
        print(f"Found {len(duplicate_errors)} duplicate headers")
        for error in duplicate_errors:
            print(f"  - Removing duplicate at line {error.line_num}: {error.headline_text}")
    
    # Remove marked duplicates
    headlines = remove_marked_headers(headlines)
    
    # Handle unclear headers
    unclear_errors = handle_unclear_headers(headlines)
    if unclear_errors:
        print(f"Assigned layers to {len(unclear_errors)} unclear headers")
        for error in unclear_errors:
            print(f"  - Line {error.line_num}: assigned layer {error.details['assigned_layer']}")
    
    # Detect layer skips (after handling unclear headers)
    layer_skip_errors = detect_layer_skips(headlines)
    
    # Process layer skip errors and create LLM prompt data
    for error in layer_skip_errors:
        prompt_data = create_llm_prompt_data(error, headlines, pattern_trackers, language, input_file)
        print(f"Layer skip detected at line {error.line_num}: {error.headline_text}")
        
        # Import and call prompt construction
        from prompt_construction import construct_prompt
        generated_prompt = construct_prompt(prompt_data)
        
        print("\n" + "="*80)
        print("GENERATED LLM PROMPT:")
        print("="*80)
        print(generated_prompt)
        print("="*80 + "\n")
        
        # TODO: Send to LLM for resolution
            
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            
            if duplicate_errors:
                f.write(f"**Info: {len(duplicate_errors)} duplicate headers removed**\n")
            if unclear_errors:
                f.write(f"**Info: {len(unclear_errors)} unclear headers assigned inherited layers**\n")
            if layer_skip_errors:
                f.write(f"**Warning: {len(layer_skip_errors)} layer skip errors detected**\n")
            f.write("\n")
            
            for headline in headlines:
                layer_text = headline['layer_text']
                if headline.get('inherited_layer', False):
                    layer_text += " [INHERITED]"
                f.write(f"Line {headline['line_num']}: {layer_text}\n")
    except Exception as e:
        print(f"Error writing output file: {e}")

// ... rest of existing code ...
```

The key additions:

1. **`detect_duplicate_headers()`**: 
   - Finds headers where one is a substring of another
   - Marks the longer one for removal (assuming it has the page number)
   - Creates error cases for tracking

2. **`handle_unclear_headers()`**:
   - Finds headers with "unclear" layer
   - Assigns them the same layer as the previous valid header
   - Marks them as having inherited layers
   - Adds a note about no numeral pattern

3. **`remove_marked_headers()`**:
   - Filters out headers marked for removal

4. **Enhanced processing flow**:
   - First handles duplicates and removes them
   - Then handles unclear headers by assigning inherited layers
   - Finally detects layer skips (after cleanup)

5. **Enhanced output**:
   - Shows statistics about duplicates removed and unclear headers handled
   - Marks inherited layers with `[INHERITED]` in the output file

This will now handle your examples:
- `"IX. Kontrollfragen 271"` and `"IX. Kontrollfragen"` → removes the longer one
- `"Empfehlungen zur vertiefenden Lektüre:"` → gets assigned the same layer as the previous header with `[INHERITED]` marking

---

_**User**_

thanks. Can you annotate or group the functions now better, so it is clear what belongs to what error type and in what order they get executed? Please write the comments for functions above the "def function" line, so I can see what a function does even when it is collapsed

---

_**Assistant**_

Absolutely! Let me reorganize and annotate the functions with clear grouping and execution order comments:

```python:backend/processing/headlines.py
import re
import os

# =============================================================================
# CORE CLASSES AND DATA STRUCTURES
# =============================================================================

class PatternTracker:
    def __init__(self, pattern_type):
        self.pattern_type = pattern_type
        self.layer = None
        
        if pattern_type == 'roman':
            self.sequence = ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.', 'VII.', 'VIII.', 'IX.', 'X.',
                           'XI.', 'XII.', 'XIII.', 'XIV.', 'XV.', 'XVI.', 'XVII.', 'XVIII.', 'XIX.', 'XX.']
        elif pattern_type == 'upper_letter':
            self.sequence = [f"{chr(i)}." for i in range(65, 91)]  # A. to Z.
        elif pattern_type == 'number':
            self.sequence = [f"{i}." for i in range(1, 101)]  # 1. to 100.
        elif pattern_type == 'lower_paren':
            self.sequence = [f"{chr(i)})" for i in range(97, 123)]  # a) to z)
            
        self.current_idx = 0
        self.first_value = self.sequence[0] if self.sequence else None
    
    def matches_next(self, text):
        """Check if text matches the next expected value in the sequence"""
        if self.current_idx >= len(self.sequence):
            return False
        return text.startswith(self.sequence[self.current_idx])
    
    def matches_first(self, text):
        """Check if text matches the first value in the sequence"""
        return text.startswith(self.first_value)
    
    def advance(self):
        self.current_idx += 1
        
    def reset(self):
        """Reset the tracker to start from the beginning of its sequence"""
        self.current_idx = 1  # Set to 1 because we just found the first value

# Pattern metadata for LLM prompting
PATTERN_METADATA = {
    'roman': {
        'name_en': 'Roman numerals',
        'name_de': 'Römische Ziffern',
        'sample_numerals': 'I., II., III.'
    },
    'upper_letter': {
        'name_en': 'Uppercase letters',
        'name_de': 'Großbuchstaben',
        'sample_numerals': 'A., B., C.'
    },
    'number': {
        'name_en': 'Arabic numbers',
        'name_de': 'Arabische Zahlen',
        'sample_numerals': '1., 2., 3.'
    },
    'lower_paren': {
        'name_en': 'Lowercase letters with parentheses',
        'name_de': 'Kleinbuchstaben mit Klammern',
        'sample_numerals': 'a), b), c)'
    }
}

class ErrorCase:
    def __init__(self, error_type, line_num, headline_text, details):
        self.error_type = error_type
        self.line_num = line_num
        self.headline_text = headline_text
        self.details = details

# =============================================================================
# BASIC UTILITY FUNCTIONS
# =============================================================================

# Detects document language (German vs English) based on common German words
def detect_language(headlines):
    """
    Simple heuristic to detect if document is German or English
    Based on common German words in headlines
    """
    german_indicators = ['und', 'der', 'die', 'das', 'nach', 'gegen', 'von', 'zur', 'zum', 'Entscheidung', 'Verfahren']
    german_count = 0
    total_words = 0
    
    for headline in headlines:
        if 'cleaned_text' in headline:
            words = headline['cleaned_text'].lower().split()
            total_words += len(words)
            german_count += sum(1 for word in words if word in german_indicators)
    
    # If more than 10% of words are German indicators, consider it German
    return 'de' if total_words > 0 and (german_count / total_words) > 0.1 else 'en'

# Gets layer metadata (name, numerals) for a specific layer number from pattern trackers
def get_layer_info(layer_num, pattern_trackers, language):
    """
    Get information about a specific layer for LLM prompting
    """
    for pattern_type, tracker in pattern_trackers.items():
        if tracker.layer == layer_num:
            metadata = PATTERN_METADATA[pattern_type]
            return {
                'layer_name': metadata[f'name_{language}'],
                'layer_numerals': metadata['sample_numerals'],
                'pattern_type': pattern_type
            }
    return None

# =============================================================================
# ERROR TYPE 1: DUPLICATE HEADERS (Execution Order: 1st)
# Handles headers that appear multiple times, often with page numbers appended
# =============================================================================

# Detects duplicate headers where one is substring of another (page number issue)
def detect_duplicate_headers(headlines):
    """
    Detect duplicate headers, especially those with page numbers incorrectly parsed
    """
    error_cases = []
    
    for i in range(len(headlines)):
        current = headlines[i]
        
        # Skip if current header is already marked for removal
        if current.get('marked_for_removal', False):
            continue
            
        for j in range(i + 1, len(headlines)):
            other = headlines[j]
            
            # Skip if other header is already marked for removal
            if other.get('marked_for_removal', False):
                continue
            
            current_text = current['cleaned_text'].strip()
            other_text = other['cleaned_text'].strip()
            
            # Check if one header is a substring of another (indicating page number issue)
            if current_text in other_text or other_text in current_text:
                # Mark the longer one for removal (it likely has the page number)
                if len(current_text) > len(other_text):
                    current['marked_for_removal'] = True
                    error_case = ErrorCase(
                        error_type="duplicate_header",
                        line_num=current['line_num'],
                        headline_text=current['cleaned_text'],
                        details={
                            'duplicate_of_line': other['line_num'],
                            'duplicate_of_text': other['cleaned_text'],
                            'action': 'remove_longer'
                        }
                    )
                else:
                    other['marked_for_removal'] = True
                    error_case = ErrorCase(
                        error_type="duplicate_header",
                        line_num=other['line_num'],
                        headline_text=other['cleaned_text'],
                        details={
                            'duplicate_of_line': current['line_num'],
                            'duplicate_of_text': current['cleaned_text'],
                            'action': 'remove_longer'
                        }
                    )
                
                error_cases.append(error_case)
                break  # Move to next header once we found a duplicate
    
    return error_cases

# Removes headers that have been marked for removal during duplicate detection
def remove_marked_headers(headlines):
    """
    Remove headers that have been marked for removal
    """
    return [h for h in headlines if not h.get('marked_for_removal', False)]

# =============================================================================
# ERROR TYPE 2: UNCLEAR HEADERS (Execution Order: 2nd)
# Handles headers without recognizable numeral patterns by inheriting from previous header
# =============================================================================

# Assigns unclear headers the same layer as the previous valid header
def handle_unclear_headers(headlines):
    """
    Assign unclear headers the same layer as the previous header
    """
    error_cases = []
    
    for i in range(len(headlines)):
        current = headlines[i]
        
        # Skip headers marked for removal
        if current.get('marked_for_removal', False):
            continue
            
        if current['layer'] == "unclear":
            # Find the previous valid header
            previous_layer = None
            for j in range(i - 1, -1, -1):
                prev_header = headlines[j]
                if (not prev_header.get('marked_for_removal', False) and 
                    isinstance(prev_header['layer'], int)):
                    previous_layer = prev_header['layer']
                    break
            
            if previous_layer is not None:
                # Assign the same layer as previous header
                current['layer'] = previous_layer
                current['layer_text'] = f"Layer {previous_layer}: {current['cleaned_text']} (inherited layer - no numeral pattern)"
                current['inherited_layer'] = True
                
                error_case = ErrorCase(
                    error_type="unclear_header_assigned",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'assigned_layer': previous_layer,
                        'reason': 'no_numeral_pattern'
                    }
                )
                error_cases.append(error_case)
            else:
                # No previous layer found, assign layer 1 as fallback
                current['layer'] = 1
                current['layer_text'] = f"Layer 1: {current['cleaned_text']} (fallback layer - no numeral pattern)"
                current['inherited_layer'] = True
                
                error_case = ErrorCase(
                    error_type="unclear_header_assigned",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'assigned_layer': 1,
                        'reason': 'no_numeral_pattern_fallback'
                    }
                )
                error_cases.append(error_case)
    
    return error_cases

# =============================================================================
# ERROR TYPE 3: LAYER SKIPS (Execution Order: 3rd)
# Detects and handles cases where layer hierarchy jumps (e.g., layer 2 to layer 4)
# These require LLM intervention for resolution
# =============================================================================

# Detects cases where layers are skipped (e.g., layer 4 after layer 2)
def detect_layer_skips(headlines):
    """
    Detect cases where layers are skipped (e.g., layer 4 after layer 2)
    """
    error_cases = []
    
    for i in range(1, len(headlines)):
        current = headlines[i]
        previous = headlines[i-1]
        
        # Only check numeric layers
        if (isinstance(current['layer'], int) and isinstance(previous['layer'], int)):
            layer_jump = current['layer'] - previous['layer']
            
            # Check for downward skips (layer increases by more than 1)
            if layer_jump > 1:
                skipped_layers = list(range(previous['layer'] + 1, current['layer']))
                
                error_case = ErrorCase(
                    error_type="layer_skip",
                    line_num=current['line_num'],
                    headline_text=current['cleaned_text'],
                    details={
                        'previous_layer': previous['layer'],
                        'current_layer': current['layer'],
                        'skipped_layers': skipped_layers,
                        'previous_headline': previous['cleaned_text'],
                        'previous_line_num': previous['line_num']
                    }
                )
                error_cases.append(error_case)
    
    return error_cases

# Extracts text content from previous correct header through next correct header
def extract_section_text(error_case, headlines, input_file):
    """
    Extract the actual text content from the last correct header to the next correct header (inclusive)
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    
    # Include the next correct header by extending to the line AFTER it
    if end_index < len(headlines):
        # If there's a header after the next correct one, go up to that line
        if end_index + 1 < len(headlines):
            end_line = headlines[end_index + 1]['line_num']
        else:
            # If this is the last header, include some lines after it
            end_line = headlines[end_index]['line_num'] + 10  # Include 10 lines after the last header
    else:
        end_line = None
    
    # Read the actual text content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Extract the relevant section
        if end_line and end_line <= len(lines):
            section_lines = lines[start_line-1:end_line-1]  # -1 because line numbers are 1-based
        elif end_line:
            # If end_line exceeds file length, just go to end of file
            section_lines = lines[start_line-1:]
        else:
            section_lines = lines[start_line-1:]
        
        section_text = ''.join(section_lines).strip()
        
    except Exception as e:
        print(f"Error reading section text: {e}")
        section_text = "Error reading section text"
    
    return section_text

# Finds all headers that share the same problematic layer as the error case
def find_problematic_headers_same_layer(error_case, headlines):
    """
    Find all headers that have the same problematic layer as the error case
    """
    problematic_layer = None
    error_index = None
    
    # Find the error case in headlines
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            problematic_layer = headline['layer']
            error_index = i
            break
    
    if problematic_layer is None or error_index is None:
        return []
    
    problematic_headers = []
    
    # Look forward from the error case to find all headers of the same problematic layer
    for i in range(error_index, len(headlines)):
        headline = headlines[i]
        if headline['layer'] == problematic_layer:
            problematic_headers.append({
                'line_num': headline['line_num'],
                'text': headline['cleaned_text']
            })
        elif isinstance(headline['layer'], int) and headline['layer'] != problematic_layer:
            # Stop when we hit a different valid layer
            break
    
    return problematic_headers

# Creates structured data for LLM prompting based on the error case
def create_llm_prompt_data(error_case, headlines, pattern_trackers, language, input_file):
    """
    Create structured data for LLM prompting based on error case
    """
    prompt_data = {
        'error_type': error_case.error_type,
        'language': language,
        'problematic_headline': error_case.headline_text,
        'line_number': error_case.line_num
    }
    
    if error_case.error_type == "layer_skip":
        details = error_case.details
        
        # Get layer information
        previous_layer_info = get_layer_info(details['previous_layer'], pattern_trackers, language)
        current_layer_info = get_layer_info(details['current_layer'], pattern_trackers, language)
        
        # Get expected layer information for skipped layers
        expected_layers_info = []
        for skipped_layer in details['skipped_layers']:
            layer_info = get_layer_info(skipped_layer, pattern_trackers, language)
            if layer_info:
                expected_layers_info.append({
                    'layer_num': skipped_layer,
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                })
        
        # Get ALL layer information for complete context
        all_layers_info = {}
        max_layer = max(details['previous_layer'], details['current_layer'])
        for layer_num in range(1, max_layer + 1):
            layer_info = get_layer_info(layer_num, pattern_trackers, language)
            if layer_info:
                all_layers_info[layer_num] = {
                    'layer_name': layer_info['layer_name'],
                    'layer_numerals': layer_info['layer_numerals']
                }
        
        # Find the section text (actual content)
        section_text = extract_section_text(error_case, headlines, input_file)
        
        # Find all problematic headers of the same layer
        problematic_headers = find_problematic_headers_same_layer(error_case, headlines)
        
        prompt_data.update({
            'previous_layer': details['previous_layer'],
            'current_layer': details['current_layer'],
            'skipped_layers': details['skipped_layers'],
            'previous_headline': details['previous_headline'],
            'previous_line_num': details['previous_line_num'],
            'previous_layer_name': previous_layer_info['layer_name'] if previous_layer_info else 'Unknown',
            'previous_layer_numerals': previous_layer_info['layer_numerals'] if previous_layer_info else 'Unknown',
            'current_layer_name': current_layer_info['layer_name'] if current_layer_info else 'Unknown',
            'current_layer_numerals': current_layer_info['layer_numerals'] if current_layer_info else 'Unknown',
            'expected_layers_info': expected_layers_info,
            'all_layers_info': all_layers_info,
            'section_text': section_text,
            'problematic_headers': problematic_headers
        })
    
    return prompt_data

# =============================================================================
# MAIN PROCESSING FUNCTION
# Execution Order: Initial headline extraction → Error handling (1,2,3) → Output
# =============================================================================

# Main function that orchestrates the entire headline extraction and error handling process
def extract_headlines_with_hierarchy(input_file, output_file):
    # Initialize pattern trackers
    roman_tracker = PatternTracker('roman')
    letter_tracker = PatternTracker('upper_letter')
    number_tracker = PatternTracker('number')
    lower_paren_tracker = PatternTracker('lower_paren')
    
    pattern_trackers = {
        'roman': roman_tracker,
        'upper_letter': letter_tracker,
        'number': number_tracker,
        'lower_paren': lower_paren_tracker
    }
    
    headlines = []
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File {input_file} not found.")
        return
        
    # PHASE 1: Extract headlines and assign initial layers
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        if line.startswith('##'):
            headline_text = line.lstrip('#').strip()
            headline_text = headline_text.strip('*').strip()
            
            matched_tracker = None
            
            # First, try to match with next expected value in each pattern
            for tracker in pattern_trackers.values():
                if tracker.matches_next(headline_text):
                    matched_tracker = tracker
                    if tracker.layer is None:
                        used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                        if not used_layers:
                            tracker.layer = 1
                        else:
                            tracker.layer = max(used_layers) + 1
                    tracker.advance()
                    break
            
            # If no match found, check if it matches the first value of any pattern
            if not matched_tracker:
                for tracker in pattern_trackers.values():
                    if tracker.matches_first(headline_text):
                        matched_tracker = tracker
                        if tracker.layer is None:
                            used_layers = {t.layer for t in pattern_trackers.values() if t.layer is not None}
                            if not used_layers:
                                tracker.layer = 1
                            else:
                                tracker.layer = max(used_layers) + 1
                        tracker.reset()
                        break
            
            if matched_tracker:
                layer = matched_tracker.layer
                layer_text = f"Layer {layer}: {headline_text}"
            else:
                layer = "unclear"
                layer_text = f"Layer unclear: {headline_text}"

            headlines.append({
                'line_num': line_num,
                'layer_text': layer_text,
                'layer': layer,
                'cleaned_text': headline_text,
                'original_text': line,
                'inherited_layer': False
            })
    
    # PHASE 2: Language detection
    language = detect_language(headlines)
    print(f"Detected language: {language}")
    
    # PHASE 3: Error handling in order
    
    # ERROR TYPE 1: Handle duplicates first (execution order: 1st)
    duplicate_errors = detect_duplicate_headers(headlines)
    if duplicate_errors:
        print(f"Found {len(duplicate_errors)} duplicate headers")
        for error in duplicate_errors:
            print(f"  - Removing duplicate at line {error.line_num}: {error.headline_text}")
    
    # Remove marked duplicates
    headlines = remove_marked_headers(headlines)
    
    # ERROR TYPE 2: Handle unclear headers (execution order: 2nd)
    unclear_errors = handle_unclear_headers(headlines)
    if unclear_errors:
        print(f"Assigned layers to {len(unclear_errors)} unclear headers")
        for error in unclear_errors:
            print(f"  - Line {error.line_num}: assigned layer {error.details['assigned_layer']}")
    
    # ERROR TYPE 3: Detect layer skips (execution order: 3rd - requires LLM)
    layer_skip_errors = detect_layer_skips(headlines)
    
    # Process layer skip errors and create LLM prompt data
    for error in layer_skip_errors:
        prompt_data = create_llm_prompt_data(error, headlines, pattern_trackers, language, input_file)
        print(f"Layer skip detected at line {error.line_num}: {error.headline_text}")
        
        # Import and call prompt construction
        from prompt_construction import construct_prompt
        generated_prompt = construct_prompt(prompt_data)
        
        print("\n" + "="*80)
        print("GENERATED LLM PROMPT:")
        print("="*80)
        print(generated_prompt)
        print("="*80 + "\n")
        
        # TODO: Send to LLM for resolution
    
    # PHASE 4: Write output file
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Extracted Headlines with Hierarchy\n\n")
            
            if duplicate_errors:
                f.write(f"**Info: {len(duplicate_errors)} duplicate headers removed**\n")
            if unclear_errors:
                f.write(f"**Info: {len(unclear_errors)} unclear headers assigned inherited layers**\n")
            if layer_skip_errors:
                f.write(f"**Warning: {len(layer_skip_errors)} layer skip errors detected**\n")
            f.write("\n")
            
            for headline in headlines:
                layer_text = headline['layer_text']
                if headline.get('inherited_layer', False):
                    layer_text += " [INHERITED]"
                f.write(f"Line {headline['line_num']}: {layer_text}\n")
    except Exception as e:
        print(f"Error writing output file: {e}")

# Entry point function
def main():
    base_path = "/home/lukas/projects/pdf_mindmap/backend/processing"
    input_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_processed.md")
    output_file = os.path.join(base_path, "marker_output/ZPO_temp/ZPO_headlines.md")
    
    print(f"Processing headlines from {input_file}...")
    extract_headlines_with_hierarchy(input_file, output_file)
    print(f"Output written to {output_file}")

if __name__ == "__main__":
    main()
```

Now the code is clearly organized with:

1. **Clear section headers** showing the different components
2. **Execution order** explicitly stated in the comments (1st, 2nd, 3rd)
3. **Function descriptions** above each `def` line so you can see what each function does when collapsed
4. **Logical grouping** by error type and functionality
5. **Phase markers** in the main function showing the processing flow

The execution order is now crystal clear:
1. **Phase 1**: Extract headlines and assign initial layers
2. **Phase 2**: Detect language
3. **Phase 3**: Error handling in order:
   - **ERROR TYPE 1** (1st): Duplicates → Remove
   - **ERROR TYPE 2** (2nd): Unclear headers → Inherit from previous
   - **ERROR TYPE 3** (3rd): Layer skips → Generate LLM prompts
4. **Phase 4**: Write output file

---

_**User**_

thanks. for this function that creates the text section to append to the message, it currently does copy any text after the next correct header. I only want the next correct header (after the incorrect headers and their text)

---

_**Assistant**_

I see the issue! You want to include the next correct header but not the text content that comes after it. Let me fix the `extract_section_text` function:

```python:backend/processing/headlines.py
// ... existing code ...

# Extracts text content from previous correct header through next correct header (header only, no content after)
def extract_section_text(error_case, headlines, input_file):
    """
    Extract the actual text content from the last correct header to the next correct header (inclusive, but only the header line)
    """
    # Find the index of the problematic headline
    error_index = None
    for i, headline in enumerate(headlines):
        if headline['line_num'] == error_case.line_num:
            error_index = i
            break
    
    if error_index is None:
        return ""
    
    # Find the previous correct header (the one before the error)
    start_index = error_index - 1
    while start_index >= 0:
        if isinstance(headlines[start_index]['layer'], int):
            break
        start_index -= 1
    
    # Find the next correct header after the problematic section
    end_index = error_index + 1
    problematic_layer = headlines[error_index]['layer']
    while end_index < len(headlines):
        current_headline = headlines[end_index]
        # Stop when we find a header that's not problematic (different layer or unclear)
        if (isinstance(current_headline['layer'], int) and 
            current_headline['layer'] != problematic_layer) or current_headline['layer'] == "unclear":
            break
        end_index += 1
    
    # Extract line numbers range
    start_line = headlines[start_index]['line_num'] if start_index >= 0 else 1
    
    # Include only up to and including the next correct header line (not content after it)
    if end_index < len(headlines):
        end_line = headlines[end_index]['line_num']  # Just include the header line itself
    else:
        end_line = None
    
    # Read the actual text content
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Extract the relevant section
        if end_line and end_line <= len(lines):
            section_lines = lines[start_line-1:end_line]  # Include the end_line (header)
        elif end_line:
            # If end_line exceeds file length, just go to end of file
            section_lines = lines[start_line-1:]
        else:
            section_lines = lines[start_line-1:]
        
        section_text = ''.join(section_lines).strip()
        
    except Exception as e:
        print(f"Error reading section text: {e}")
        section_text = "Error reading section text"
    
    return section_text

// ... rest of existing code ...
```

The key changes:

1. **Removed the extension beyond the next header**: Changed `end_line = headlines[end_index + 1]['line_num']` to `end_line = headlines[end_index]['line_num']`

2. **Removed the "+10 lines" logic**: No longer adding extra lines after the last header

3. **Updated slice to include the header**: Changed `lines[start_line-1:end_line-1]` to `lines[start_line-1:end_line]` to include the next correct header line

Now the section will include:
- The previous correct header and its content
- All the problematic headers and their content  
- The next correct header (just the header line itself)
- **No content after the next correct header**

This gives the LLM the exact context it needs to see the problematic section boundaries without including unrelated content that comes after.

---

